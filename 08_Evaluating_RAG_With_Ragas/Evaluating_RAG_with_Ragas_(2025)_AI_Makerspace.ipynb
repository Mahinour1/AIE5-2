{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLokDKoN1aKv"
      },
      "source": [
        "# Using Ragas to Evaluate a RAG Application built with LangChain and LangGraph\n",
        "\n",
        "In the following notebook, we'll be looking at how [Ragas](https://github.com/explodinggradients/ragas) can be helpful in a number of ways when looking to evaluate your RAG applications!\n",
        "\n",
        "While this example is rooted in LangChain/LangGraph - Ragas is framework agnostic (you don't even need to be using a framework!).\n",
        "\n",
        "-  Breakout Room #1\n",
        "  1. Task 1: Installing Required Libraries\n",
        "  2. Task 2: Set Environment Variables\n",
        "  3. Task 3: Synthetic Dataset Generation for Evaluation using Ragas\n",
        "  4. Task 4: Evaluating our Pipeline with Ragas\n",
        "  5. Task 6: Making Adjustments and Re-Evaluating\n",
        "\n",
        "But first! Let's set some dependencies!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k9tqHdq2BGi"
      },
      "source": [
        "## Dependencies and API Keys:\n",
        "\n",
        "> NOTE: Please skip the pip install commands if you are running the notebook locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "njvrpsHWifeS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74fc307c-4337-4f94-efa6-a54a1cc8ea79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/175.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m175.7/175.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/45.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m413.0/413.0 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU ragas==0.2.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DjesmARj2I4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83984927-7876-4855-9d3c-71db35aa0d1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m532.5/981.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m137.2/137.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m326.9/326.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m306.6/306.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m167.1/167.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m63.6/63.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m300.7/300.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain-community==0.3.14 langchain-openai==0.2.14 unstructured==0.16.12 langgraph==0.2.61 langchain-qdrant==0.2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3d5seTX2xyx"
      },
      "source": [
        "We'll also need to provide our API keys.\n",
        "\n",
        "First, OpenAI's for our LLM/embedding model combination!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_J02wP3gdLds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "921e86e5-ac91-43c6-a74f-cf97ddb9f642"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your OpenAI API key!路路路路路路路路路路\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Please enter your OpenAI API key!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU9cDbFa23oP"
      },
      "source": [
        "**OPTIONALLY**:\n",
        "\n",
        "We can also provide a Ragas API key - which you can sign-up for [here](https://app.ragas.io/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dInPQkxfUhg"
      },
      "outputs": [],
      "source": [
        "os.environ[\"RAGAS_APP_TOKEN\"] = getpass(\"Please enter your Ragas API key!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zTz1-4U3Hg0"
      },
      "source": [
        "## Generating Synthetic Test Data\n",
        "\n",
        "We wil be using Ragas to build out a set of synthetic test questions, references, and reference contexts. This is useful because it will allow us to find out how our system is performing.\n",
        "\n",
        "> NOTE: Ragas is best suited for finding *directional* changes in your LLM-based systems. The absolute scores aren't comparable in a vacuum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pssK40Eh4MIc"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We'll prepare our data - and download our webpages which we'll be using for our data today.\n",
        "\n",
        "These webpages are from [Simon Willison's](https://simonwillison.net/) yearly \"AI learnings\".\n",
        "\n",
        "- [2023 Blog](https://simonwillison.net/2023/Dec/31/ai-in-2023/)\n",
        "- [2024 Blog](https://simonwillison.net/2024/Dec/31/llms-in-2024/)\n",
        "\n",
        "Let's start by collecting our data into a useful pile!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "12cpcowvhW3O"
      },
      "outputs": [],
      "source": [
        "!mkdir data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAHtGwnsfiA5",
        "outputId": "b6a884b9-1066-4cf1-ea9a-80f886c74490"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 31314    0 31314    0     0  71625      0 --:--:-- --:--:-- --:--:-- 71821\n"
          ]
        }
      ],
      "source": [
        "!curl https://simonwillison.net/2023/Dec/31/ai-in-2023/ -o data/2023_llms.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEs60mX1hB_a",
        "outputId": "27eb6428-5a33-4477-a299-e8f16c6f8367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 70173    0 70173    0     0   425k      0 --:--:-- --:--:-- --:--:--  425k\n"
          ]
        }
      ],
      "source": [
        "!curl https://simonwillison.net/2024/Dec/31/llms-in-2024/ -o data/2024_llms.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfKQgiR14Omj"
      },
      "source": [
        "Next, let's load our data into a familiar LangChain format using the `DirectoryLoader`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dTYMPlsTiDRe"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "\n",
        "path = \"data/\"\n",
        "loader = DirectoryLoader(path, glob=\"*.html\")\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfyA65MM4Tbn"
      },
      "source": [
        "### Knowledge Graph Based Synthetic Generation\n",
        "\n",
        "Ragas uses a knowledge graph based approach to create data. This is extremely useful as it allows us to create complex queries rather simply. The additional testset complexity allows us to evaluate larger problems more effectively, as systems tend to be very strong on simple evaluation tasks.\n",
        "\n",
        "Let's start by defining our `generator_llm` (which will generate our questions, summaries, and more), and our `generator_embeddings` which will be useful in building our graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbZ9j1EL-X55"
      },
      "source": [
        "### Abstracted SDG\n",
        "\n",
        "The above method is the full process - but we can shortcut that using the provided abstractions!\n",
        "\n",
        "This will generate our knowledge graph under the hood, and will - from there - generate our personas and scenarios to construct our queries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gFa25mrYq-58"
      },
      "outputs": [],
      "source": [
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "9f6ed158ee714d57a015e175dc8d1074",
            "cb42c1780bf143ce99fc4fd5d9552195",
            "1a64719b314441319342706039afeaa5",
            "eba67208fa2d463c80b611c10a764c2b",
            "dec4d800cdc748598336de4a5179f9f8",
            "7d974d2c41fe4f87abf558752c52ff22",
            "ac4d0e3f185b448e9ae8f1a69aac9c9a",
            "02b895c7622a4e1289181c0daccb7d16",
            "81bd7a5831504edca34934746239a4d5",
            "045876c0ffc349cfa7a219156cc562d5",
            "7b563c1b2ed8429093077b52df64c3c3",
            "bc1d72296b974395a03d2beacbe3fe49",
            "419683ea18d74012a3af5f7fbceb7e6a",
            "52307c7ed2b249b88fa8984cc35c5b6f",
            "3a60c28ca47f4f03bbe8fb6254dcc31e",
            "621c1fe3c8df4afaa60210f3a21be202",
            "cce3960468fe425eb9749aaae123f1c3",
            "26f1876c12494fcab17bbb518682f2d0",
            "ea4622e501514546ab72e573ef7d3779",
            "3b9368b33a4b4df9ac2b538258eccbb3",
            "9b6cc06adf804d69819c9e5172f9faee",
            "b469015d79db423e84d10a4d4b6ebe27",
            "346bf493b1c146729ec8719e9c6add72",
            "95868ebefccd41739b828860cb76fe48",
            "80b7e73d6b0140a0b81d2dae7de5fc8e",
            "f34ac2d41036487b86df330b5d499d8f",
            "b4218459e5884b328191982138e4d8ab",
            "12bf4c503cad4fc6accaac5b63a33efc",
            "efa5784498d4451280bd7e520fc169b3",
            "fc4da7da6bd84e2290bea6ddb73b3b8e",
            "ed45493d967f431fa7f99b56574ec7c0",
            "baa82b2330914bc9aaec648427183489",
            "9a21192b7f0a4bb1a482df32c8b1674f",
            "efc621dc3bba4f7391482b6c8100036c",
            "e13e79cb3c9949c8be95a191faf4939b",
            "57257089303244d587f1e36ad17866de",
            "fda6085ab28a4f00a0ad37e3e6fba913",
            "4553b364be5d425ca80e4819f48f4121",
            "3263d40172984ece820490056b02e559",
            "ddfdc13c8f0d497ca4ff9e19d130b10d",
            "e6a39f84177f40a3813c28b4c3691e5a",
            "528e64c47f1942618edb70c60e8656e2",
            "47361f0e9c0f4543b217701d9be8a74b",
            "31d83715805a4bd481975796b667d36a",
            "5309a59d155840efbb13e1cdc1bfb92b",
            "6c1e58660719468ba4035ebd89bfe7b4",
            "a79375eefc8d41e29d6c6fa67f77f922",
            "5d4834d9ab96428bb9f43c30d0ad8e9d",
            "5422f1367de54bc99753cce6ea3a93a7",
            "86884bda9daf4d4f87870a5f180ad006",
            "fbee8356be144e4e913bc6bb3385f61d",
            "3faf9cfd273c46ce85f0947b42e0c25a",
            "c1d167c67e72404cad05daa01ee14705",
            "0b5fbaa9d4ad4d5e9f22f4f0c2643ef1",
            "eb2eb7cad66a49778bdf4567803a26fd",
            "e89d6ef0b06d44b897876e8f07397980",
            "6edb3971184f449d9d22ea06e4f2cb99",
            "585d7e95ac77494c99554aceaf595e63",
            "001a033727a9426e8cc4b0d3ffa3cee6",
            "d29265448516400281a9fd9b14984bd4",
            "1fda1054fea04125a88b5e6e8d0f0899",
            "d4b3e2d4ac7c46d0aeef3881feae06f5",
            "ca52e18515f1407c9b80e63e66e38f5e",
            "8a448799f69f4d3aaec11679886c794e",
            "d273af6f9ec94f049ba06f0971c61d7c",
            "9c9be8eed31d4067a3eab74fa97f9269",
            "fbeb65d396d141fd908ed6ad61d46434",
            "75edd75dc5614193b2fb6f9ae60edbc4",
            "cd26269e258f4ac08965543ebd75f65d",
            "a156ba773dd3413fa33d61136419a44b",
            "0944f1eea3c24f40be3953a7233aab7e",
            "3c594f560f7148cea8a46166f2edc55a",
            "a59981d0f93f45a5a1b9a70f323565c6",
            "079463ef12a443108fc46acc205e37db",
            "4694f047b45a4b38bb2ebbeca2e16a15",
            "ad96255cb05e4cadb63a39979a4679e1",
            "59273683ec9b44839b503ec23629148c",
            "f02a044d69494e31b4971b6b28b0b40b",
            "0493d8206c4c4a3490aaee0e039b7fa3",
            "1e713b3b96ed4af7a570d24274d82aef",
            "9f7f2b66957e4975960990a11903859d",
            "3aaab9d5aa354685a3b4fd1a66da8f27",
            "d2d4d15ada6b41e8838c7547a1496023",
            "b035f9e28e894e019664988458943c57",
            "3b12d8cbf7274575a516bdbac4bbca70",
            "00af77119df9499594e6c7c52205f0ce",
            "20c24e354e944b399af17cfdd19e05bb",
            "04fbb6e5dd9a4d2f962460293d440db6",
            "6b2a95b93f28430b9a76b4bfc82f07a1",
            "5db0d833c6e54d43be635c36bfd376a9",
            "6503d2d3920e4e3b86cd1f4f80aed818",
            "477a27aa344946f4aa77c3da7428b746",
            "6743c3ce8f794051a8d555eceddda15f",
            "7cf2b6b9a08544d0a2a775481c3c6120",
            "750134f23399437980f8fd757ed034f2",
            "e9b1fe1ad4f64cff88240470c7442e86",
            "66f2eb93aa334c1da8226f15ecc91840",
            "c657153e7bca482193cd3b424627c07f",
            "67837c39ac9440c18997de05a3334b9b"
          ]
        },
        "id": "ZvXsRbwIlfm1",
        "outputId": "6ec07576-2344-4a26-b81a-63e41e5fa40d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f6ed158ee714d57a015e175dc8d1074",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlinesExtractor:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc1d72296b974395a03d2beacbe3fe49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlineSplitter:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "346bf493b1c146729ec8719e9c6add72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efc621dc3bba4f7391482b6c8100036c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5309a59d155840efbb13e1cdc1bfb92b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/26 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e89d6ef0b06d44b897876e8f07397980"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating personas:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbeb65d396d141fd908ed6ad61d46434"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f02a044d69494e31b4971b6b28b0b40b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b2a95b93f28430b9a76b4bfc82f07a1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "dataset = generator.generate_with_langchain_docs(docs, testset_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "1jsrtjNllwiI",
        "outputId": "df8095df-ac03-4d5a-965b-e5efabfd604d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           user_input  \\\n",
              "0   What advancements has OpenAI made in the field...   \n",
              "1     Wht is Anthropic's cheepest model and its cost?   \n",
              "2   What was the initial challenge with OpenAI's W...   \n",
              "3   What does it mean when someone says a prompt w...   \n",
              "4   How has the increased energy efficiency of AI ...   \n",
              "5   How do the criticisms of LLMs, particularly re...   \n",
              "6   How has the concept of universal access to AI ...   \n",
              "7   Why LLMs need better criticism and what are th...   \n",
              "8   How does the Claude 3.5 Sonnet compare to othe...   \n",
              "9   How have the advancements in Llama 3.2 models ...   \n",
              "10  How do the pricing and capabilities of GPT-4o ...   \n",
              "11  In light of the advancements in Large Language...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [Prompt driven app generation is a commodity a...   \n",
              "1   [gets you OpenAIs most expensive model, o1. G...   \n",
              "2   [feed with the model and talk about what you c...   \n",
              "3   [dependent on AGI itself. A model thats robus...   \n",
              "4   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "5   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "6   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "7   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "8   [<1-hop>\\n\\nthat. DeepSeek v3 is a huge 685B p...   \n",
              "9   [<1-hop>\\n\\neasy to follow. The rest of the do...   \n",
              "10  [<1-hop>\\n\\nfeed with the model and talk about...   \n",
              "11  [<1-hop>\\n\\nSimon Willisons Weblog Subscribe ...   \n",
              "\n",
              "                                            reference  \\\n",
              "0   In 2024, OpenAI's GPT-4 model, which was once ...   \n",
              "1   Anthropics cheapest model is Claude 3 Haiku, ...   \n",
              "2   OpenAI started with a WebSocket API that was q...   \n",
              "3   A prompt without the evals, models, and especi...   \n",
              "4   The increased energy efficiency of AI models h...   \n",
              "5   The criticisms of LLMs, especially concerning ...   \n",
              "6   In 2024, the concept of universal access to AI...   \n",
              "7   LLMs need better criticism because there are s...   \n",
              "8   Claude 3.5 Sonnet is benchmarked alongside oth...   \n",
              "9   Recent advancements in Llama 3.2 models have d...   \n",
              "10  GPT-4o is significantly cheaper than GPT-4, wi...   \n",
              "11  Throughout 2024, significant advancements in L...   \n",
              "\n",
              "                        synthesizer_name  \n",
              "0   single_hop_specifc_query_synthesizer  \n",
              "1   single_hop_specifc_query_synthesizer  \n",
              "2   single_hop_specifc_query_synthesizer  \n",
              "3   single_hop_specifc_query_synthesizer  \n",
              "4   multi_hop_abstract_query_synthesizer  \n",
              "5   multi_hop_abstract_query_synthesizer  \n",
              "6   multi_hop_abstract_query_synthesizer  \n",
              "7   multi_hop_abstract_query_synthesizer  \n",
              "8   multi_hop_specific_query_synthesizer  \n",
              "9   multi_hop_specific_query_synthesizer  \n",
              "10  multi_hop_specific_query_synthesizer  \n",
              "11  multi_hop_specific_query_synthesizer  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a40ef2c4-1431-4649-85fa-7983126aa0c8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What advancements has OpenAI made in the field...</td>\n",
              "      <td>[Prompt driven app generation is a commodity a...</td>\n",
              "      <td>In 2024, OpenAI's GPT-4 model, which was once ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wht is Anthropic's cheepest model and its cost?</td>\n",
              "      <td>[gets you OpenAIs most expensive model, o1. G...</td>\n",
              "      <td>Anthropics cheapest model is Claude 3 Haiku, ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What was the initial challenge with OpenAI's W...</td>\n",
              "      <td>[feed with the model and talk about what you c...</td>\n",
              "      <td>OpenAI started with a WebSocket API that was q...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What does it mean when someone says a prompt w...</td>\n",
              "      <td>[dependent on AGI itself. A model thats robus...</td>\n",
              "      <td>A prompt without the evals, models, and especi...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How has the increased energy efficiency of AI ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>The increased energy efficiency of AI models h...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How do the criticisms of LLMs, particularly re...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>The criticisms of LLMs, especially concerning ...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How has the concept of universal access to AI ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>In 2024, the concept of universal access to AI...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Why LLMs need better criticism and what are th...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>LLMs need better criticism because there are s...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How does the Claude 3.5 Sonnet compare to othe...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nthat. DeepSeek v3 is a huge 685B p...</td>\n",
              "      <td>Claude 3.5 Sonnet is benchmarked alongside oth...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How have the advancements in Llama 3.2 models ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\neasy to follow. The rest of the do...</td>\n",
              "      <td>Recent advancements in Llama 3.2 models have d...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How do the pricing and capabilities of GPT-4o ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nfeed with the model and talk about...</td>\n",
              "      <td>GPT-4o is significantly cheaper than GPT-4, wi...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>In light of the advancements in Large Language...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nSimon Willisons Weblog Subscribe ...</td>\n",
              "      <td>Throughout 2024, significant advancements in L...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a40ef2c4-1431-4649-85fa-7983126aa0c8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a40ef2c4-1431-4649-85fa-7983126aa0c8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a40ef2c4-1431-4649-85fa-7983126aa0c8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f3224b18-1122-42c6-a260-4195fa60f145\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f3224b18-1122-42c6-a260-4195fa60f145')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f3224b18-1122-42c6-a260-4195fa60f145 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"user_input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"How do the pricing and capabilities of GPT-4o compare to GPT-4, and what impact does this have on the accessibility and environmental concerns of LLMs?\",\n          \"How have the advancements in Llama 3.2 models and the environmental impact of LLMs been addressed in recent AI developments?\",\n          \"What advancements has OpenAI made in the field of large language models, and how do they compare to other organizations' models in 2024?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference_contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"GPT-4o is significantly cheaper than GPT-4, with a cost of $2.50, which is 12 times cheaper than GPT-4. Additionally, GPT-4o mini is priced at $0.15 per million tokens, making it nearly 7 times cheaper than GPT-3.5. This reduction in price is attributed to increased competition and efficiency, which also addresses environmental concerns by reducing the energy cost of running prompts. The lower pricing and increased capabilities of GPT-4o make it more accessible to users, although the era of free access to the best models has ended with the introduction of subscription services like ChatGPT Pro.\",\n          \"Recent advancements in Llama 3.2 models have demonstrated significant improvements in efficiency and capability, particularly with their ability to run on smaller devices like iPhones using the MLC Chat iOS app. These models, despite their smaller size of 1B and 3B, perform impressively well, showcasing the potential for high performance in compact models. This development is part of a broader trend in the AI industry towards increasing model efficiency, which has also contributed to a reduction in the environmental impact of running large language models (LLMs). While the environmental impact initially worsened, improvements in training and inference performance have led to more sustainable practices. The focus on efficiency has not only reduced costs but also mitigated some of the environmental concerns associated with LLMs.\",\n          \"In 2024, OpenAI's GPT-4 model, which was once the leading large language model, has been surpassed by models from 18 different organizations on the Chatbot Arena Leaderboard. These organizations include Google, Alibaba, Anthropic, Meta, and others. The advancements in large language models have been significant, with models now capable of handling much longer input contexts, such as Google's Gemini 1.5 Pro, which can accept up to 2 million tokens and input video. This has expanded the scope of problems that can be solved with LLMs. Despite the competition, OpenAI remains a key player in the field, although the achievement of surpassing GPT-4 is no longer as notable as it was in 2023.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"synthesizer_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"single_hop_specifc_query_synthesizer\",\n          \"multi_hop_abstract_query_synthesizer\",\n          \"multi_hop_specific_query_synthesizer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.to_pandas().to_csv('ragas_data_2.csv')\n"
      ],
      "metadata": {
        "id": "NUty642_HHuM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFMVNyJn-7bT"
      },
      "source": [
        "#### OPTIONAL:\n",
        "\n",
        "If you've provided your Ragas API key - you can use this web interface to look at the created data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "VEXOV88Vly5I",
        "outputId": "65f4f5e9-f180-4996-bb12-5ee402cf4774"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testset uploaded! View at https://app.ragas.io/dashboard/alignment/testset/45d7742f-e0c6-4e85-9b66-6e819adfaec3\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'https://app.ragas.io/dashboard/alignment/testset/45d7742f-e0c6-4e85-9b66-6e819adfaec3'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni4Q14_arJYw"
      },
      "source": [
        "## LangChain RAG\n",
        "\n",
        "Now we'll construct our LangChain RAG, which we will be evaluating using the above created test data!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGy99jkVrVqX"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "Let's start with building our retrieval pipeline, which will involve loading the same data we used to create our synthetic test set above.\n",
        "\n",
        "> NOTE: We need to use the same data - as our test set is specifically designed for this data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "847933Htono8"
      },
      "outputs": [],
      "source": [
        "path = \"data/\"\n",
        "loader = DirectoryLoader(path, glob=\"*.html\")\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQv3Psil_D2A"
      },
      "source": [
        "Now that we have our data loaded, let's split it into chunks!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2U0eJ_prZhL",
        "outputId": "ed3c1db8-538b-47b0-e0de-2ee8dcf96837"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "split_documents = text_splitter.split_documents(docs)\n",
        "len(split_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bwyRd7Pq-5_"
      },
      "source": [
        "####  Question:\n",
        "\n",
        "What is the purpose of the `chunk_overlap` parameter in the `RecursiveCharacterTextSplitter`?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ANSWER\n",
        "It is used to specify the number of overlapping characters between consecutive text chunks when splitting documents. This overlap helps maintain contextual continuity between chunks"
      ],
      "metadata": {
        "id": "ZaXApd3OHb91"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EcbmBBC_G2s"
      },
      "source": [
        "Next up, we'll need to provide an embedding model that we can use to construct our vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KY_CNAbfr9sY"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP_VDgyx_MPq"
      },
      "source": [
        "Now we can build our in memory QDrant vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AoxImnLJsC4Q"
      },
      "outputs": [],
      "source": [
        "from langchain_qdrant import QdrantVectorStore\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http.models import Distance, VectorParams\n",
        "\n",
        "client = QdrantClient(\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"ai_across_years\",\n",
        "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
        ")\n",
        "\n",
        "vector_store = QdrantVectorStore(\n",
        "    client=client,\n",
        "    collection_name=\"ai_across_years\",\n",
        "    embedding=embeddings,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUSCXe7x_h0O"
      },
      "source": [
        "We can now add our documents to our vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Vckrosgpsfq2"
      },
      "outputs": [],
      "source": [
        "_ = vector_store.add_documents(documents=split_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBgsT5_m_lOD"
      },
      "source": [
        "Let's define our retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qmxRJeMbskTS"
      },
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZX68nle_nUm"
      },
      "source": [
        "Now we can produce a node for retrieval!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RMuKChk8vmCv"
      },
      "outputs": [],
      "source": [
        "def retrieve(state):\n",
        "  retrieved_docs = retriever.invoke(state[\"question\"])\n",
        "  return {\"context\" : retrieved_docs}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48-mJHgUsvDG"
      },
      "source": [
        "### Augmented\n",
        "\n",
        "Let's create a simple RAG prompt!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "C0masYYKsxLg"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_PROMPT = \"\"\"\\\n",
        "You are a helpful assistant who answers questions based on provided context. You must only use the provided context, and cannot use your own knowledge.\n",
        "\n",
        "### Question\n",
        "{question}\n",
        "\n",
        "### Context\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cznU20c0uY9j"
      },
      "source": [
        "### Generation\n",
        "\n",
        "We'll also need an LLM to generate responses - we'll use `gpt-4o-mini` to avoid using the same model as our judge model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZVHBcNGptdZt"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTpV7-b7_44n"
      },
      "source": [
        "Then we can create a `generate` node!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "trgefAs-wX84"
      },
      "outputs": [],
      "source": [
        "def generate(state):\n",
        "  docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "  messages = rag_prompt.format_messages(question=state[\"question\"], context=docs_content)\n",
        "  response = llm.invoke(messages)\n",
        "  return {\"response\" : response.content}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhD1IxvXu2zX"
      },
      "source": [
        "### Building RAG Graph with LangGraph\n",
        "\n",
        "Let's create some state for our LangGraph RAG graph!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "5-o5r2mqu8Og"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import START, StateGraph\n",
        "from typing_extensions import List, TypedDict\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "class State(TypedDict):\n",
        "  question: str\n",
        "  context: List[Document]\n",
        "  response: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFEqEQje_--V"
      },
      "source": [
        "Now we can build our simple graph!\n",
        "\n",
        "> NOTE: We're using `add_sequence` since we will always move from retrieval to generation. This is essentially building a chain in LangGraph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8kMJ_bgWvU-q"
      },
      "outputs": [],
      "source": [
        "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
        "graph_builder.add_edge(START, \"retrieve\")\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKX8yupqAIeQ"
      },
      "source": [
        "Let's do a test to make sure it's doing what we'd expect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PXdB5pdbwzIF"
      },
      "outputs": [],
      "source": [
        "response = graph.invoke({\"question\" : \"How are LLM agents useful?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "JPuemnQQw5Y2",
        "outputId": "794c314b-bdb5-4c19-8037-06c65fc2df95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LLM agents are useful in several ways, particularly in the realm of software development and code generation. Here are some key points:\\n\\n1. **Ease of Building**: LLMs can be built with relatively little codejust a few hundred lines of Pythonprovided there is sufficient quality and quantity of training data. This makes them more accessible than one might initially think.\\n\\n2. **Local Operation**: Recent advancements have allowed LLMs to be run on personal devices, making them more practical for individual users without needing expensive server setups.\\n\\n3. **Effective Code Generation**: LLMs excel at writing code due to the simpler grammar rules of programming languages compared to natural languages. They can generate code effectively, and tools like ChatGPT Code Interpreter can execute and test this code, handling errors and correcting issues in real-time.\\n\\n4. **Automation of Tasks**: LLM agents are seen as potential systems that can perform tasks on behalf of users, although practical implementations in production are still limited.\\n\\n5. **Critical Engagement**: While there are valid criticisms of LLM technology, engaging critically with its capabilities and limitations can lead to better understanding and responsible use, emphasizing the need for a balanced view of their potential benefits and risks.\\n\\nOverall, LLM agents are particularly useful in programming and automation, showcasing both their effectiveness and the need for ongoing dialogue about their implications.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "response[\"response\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK5gyOlixWr4"
      },
      "source": [
        "## Evaluating the App with Ragas\n",
        "\n",
        "Now we can finally do our evaluation!\n",
        "\n",
        "We'll start by running the queries we generated usign SDG above through our application to get context and responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzstmZmfxYP2"
      },
      "outputs": [],
      "source": [
        "for test_row in dataset:\n",
        "  response = graph.invoke({\"question\" : test_row.eval_sample.user_input})\n",
        "  test_row.eval_sample.response = response[\"response\"]\n",
        "  test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 808
        },
        "id": "VLXEuORVxd0l",
        "outputId": "12de102d-8dea-46e3-8dba-7dac816863c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           user_input  \\\n",
              "0   What advancements has OpenAI made in the field...   \n",
              "1     Wht is Anthropic's cheepest model and its cost?   \n",
              "2   What was the initial challenge with OpenAI's W...   \n",
              "3   What does it mean when someone says a prompt w...   \n",
              "4   How has the increased energy efficiency of AI ...   \n",
              "5   How do the criticisms of LLMs, particularly re...   \n",
              "6   How has the concept of universal access to AI ...   \n",
              "7   Why LLMs need better criticism and what are th...   \n",
              "8   How does the Claude 3.5 Sonnet compare to othe...   \n",
              "9   How have the advancements in Llama 3.2 models ...   \n",
              "10  How do the pricing and capabilities of GPT-4o ...   \n",
              "11  In light of the advancements in Large Language...   \n",
              "\n",
              "                                   retrieved_contexts  \\\n",
              "0   [OpenAI are not the only game in town here. Go...   \n",
              "1   [Today $30/mTok gets you OpenAIs most expensi...   \n",
              "2   [Did you know ChatGPT has two entirely differe...   \n",
              "3   [Its become abundantly clear over the course ...   \n",
              "4   [The much bigger problem here is the enormous ...   \n",
              "5   [LLMs need better criticism\\n\\nA lot of people...   \n",
              "6   [In 2024, almost every significant model vendo...   \n",
              "7   [LLMs need better criticism\\n\\nA lot of people...   \n",
              "8   [Getting back to models that beat GPT-4: Anthr...   \n",
              "9   [Another common technique is to use larger mod...   \n",
              "10  [Today $30/mTok gets you OpenAIs most expensi...   \n",
              "11  [Since then, almost every major LLM (and most ...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [Prompt driven app generation is a commodity a...   \n",
              "1   [gets you OpenAIs most expensive model, o1. G...   \n",
              "2   [feed with the model and talk about what you c...   \n",
              "3   [dependent on AGI itself. A model thats robus...   \n",
              "4   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "5   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "6   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "7   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "8   [<1-hop>\\n\\nthat. DeepSeek v3 is a huge 685B p...   \n",
              "9   [<1-hop>\\n\\neasy to follow. The rest of the do...   \n",
              "10  [<1-hop>\\n\\nfeed with the model and talk about...   \n",
              "11  [<1-hop>\\n\\nSimon Willisons Weblog Subscribe ...   \n",
              "\n",
              "                                             response  \\\n",
              "0   In 2024, OpenAI has made significant advanceme...   \n",
              "1   Anthropic's cheapest model is Claude 3 Haiku, ...   \n",
              "2   The initial challenge with OpenAI's WebSocket ...   \n",
              "3   When someone says a prompt without evals is li...   \n",
              "4   The increased energy efficiency of AI models h...   \n",
              "5   The criticisms of LLMs, particularly regarding...   \n",
              "6   In 2024, the concept of universal access to AI...   \n",
              "7   LLMs (Large Language Models) need better criti...   \n",
              "8   The Claude 3.5 Sonnet model is noted for its a...   \n",
              "9   Recent advancements in Llama 3.2 models and th...   \n",
              "10  The pricing and capabilities of GPT-4o are sig...   \n",
              "11  The advancements in Large Language Models (LLM...   \n",
              "\n",
              "                                            reference  \\\n",
              "0   In 2024, OpenAI's GPT-4 model, which was once ...   \n",
              "1   Anthropics cheapest model is Claude 3 Haiku, ...   \n",
              "2   OpenAI started with a WebSocket API that was q...   \n",
              "3   A prompt without the evals, models, and especi...   \n",
              "4   The increased energy efficiency of AI models h...   \n",
              "5   The criticisms of LLMs, especially concerning ...   \n",
              "6   In 2024, the concept of universal access to AI...   \n",
              "7   LLMs need better criticism because there are s...   \n",
              "8   Claude 3.5 Sonnet is benchmarked alongside oth...   \n",
              "9   Recent advancements in Llama 3.2 models have d...   \n",
              "10  GPT-4o is significantly cheaper than GPT-4, wi...   \n",
              "11  Throughout 2024, significant advancements in L...   \n",
              "\n",
              "                        synthesizer_name  \n",
              "0   single_hop_specifc_query_synthesizer  \n",
              "1   single_hop_specifc_query_synthesizer  \n",
              "2   single_hop_specifc_query_synthesizer  \n",
              "3   single_hop_specifc_query_synthesizer  \n",
              "4   multi_hop_abstract_query_synthesizer  \n",
              "5   multi_hop_abstract_query_synthesizer  \n",
              "6   multi_hop_abstract_query_synthesizer  \n",
              "7   multi_hop_abstract_query_synthesizer  \n",
              "8   multi_hop_specific_query_synthesizer  \n",
              "9   multi_hop_specific_query_synthesizer  \n",
              "10  multi_hop_specific_query_synthesizer  \n",
              "11  multi_hop_specific_query_synthesizer  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-456e9600-9814-4ab3-b14d-25ccf1f1567a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>retrieved_contexts</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>response</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What advancements has OpenAI made in the field...</td>\n",
              "      <td>[OpenAI are not the only game in town here. Go...</td>\n",
              "      <td>[Prompt driven app generation is a commodity a...</td>\n",
              "      <td>In 2024, OpenAI has made significant advanceme...</td>\n",
              "      <td>In 2024, OpenAI's GPT-4 model, which was once ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wht is Anthropic's cheepest model and its cost?</td>\n",
              "      <td>[Today $30/mTok gets you OpenAIs most expensi...</td>\n",
              "      <td>[gets you OpenAIs most expensive model, o1. G...</td>\n",
              "      <td>Anthropic's cheapest model is Claude 3 Haiku, ...</td>\n",
              "      <td>Anthropics cheapest model is Claude 3 Haiku, ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What was the initial challenge with OpenAI's W...</td>\n",
              "      <td>[Did you know ChatGPT has two entirely differe...</td>\n",
              "      <td>[feed with the model and talk about what you c...</td>\n",
              "      <td>The initial challenge with OpenAI's WebSocket ...</td>\n",
              "      <td>OpenAI started with a WebSocket API that was q...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What does it mean when someone says a prompt w...</td>\n",
              "      <td>[Its become abundantly clear over the course ...</td>\n",
              "      <td>[dependent on AGI itself. A model thats robus...</td>\n",
              "      <td>When someone says a prompt without evals is li...</td>\n",
              "      <td>A prompt without the evals, models, and especi...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How has the increased energy efficiency of AI ...</td>\n",
              "      <td>[The much bigger problem here is the enormous ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>The increased energy efficiency of AI models h...</td>\n",
              "      <td>The increased energy efficiency of AI models h...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How do the criticisms of LLMs, particularly re...</td>\n",
              "      <td>[LLMs need better criticism\\n\\nA lot of people...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>The criticisms of LLMs, particularly regarding...</td>\n",
              "      <td>The criticisms of LLMs, especially concerning ...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How has the concept of universal access to AI ...</td>\n",
              "      <td>[In 2024, almost every significant model vendo...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>In 2024, the concept of universal access to AI...</td>\n",
              "      <td>In 2024, the concept of universal access to AI...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Why LLMs need better criticism and what are th...</td>\n",
              "      <td>[LLMs need better criticism\\n\\nA lot of people...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>LLMs (Large Language Models) need better criti...</td>\n",
              "      <td>LLMs need better criticism because there are s...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How does the Claude 3.5 Sonnet compare to othe...</td>\n",
              "      <td>[Getting back to models that beat GPT-4: Anthr...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nthat. DeepSeek v3 is a huge 685B p...</td>\n",
              "      <td>The Claude 3.5 Sonnet model is noted for its a...</td>\n",
              "      <td>Claude 3.5 Sonnet is benchmarked alongside oth...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How have the advancements in Llama 3.2 models ...</td>\n",
              "      <td>[Another common technique is to use larger mod...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\neasy to follow. The rest of the do...</td>\n",
              "      <td>Recent advancements in Llama 3.2 models and th...</td>\n",
              "      <td>Recent advancements in Llama 3.2 models have d...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How do the pricing and capabilities of GPT-4o ...</td>\n",
              "      <td>[Today $30/mTok gets you OpenAIs most expensi...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nfeed with the model and talk about...</td>\n",
              "      <td>The pricing and capabilities of GPT-4o are sig...</td>\n",
              "      <td>GPT-4o is significantly cheaper than GPT-4, wi...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>In light of the advancements in Large Language...</td>\n",
              "      <td>[Since then, almost every major LLM (and most ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nSimon Willisons Weblog Subscribe ...</td>\n",
              "      <td>The advancements in Large Language Models (LLM...</td>\n",
              "      <td>Throughout 2024, significant advancements in L...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-456e9600-9814-4ab3-b14d-25ccf1f1567a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-456e9600-9814-4ab3-b14d-25ccf1f1567a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-456e9600-9814-4ab3-b14d-25ccf1f1567a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2ea4fca1-b781-49ec-ae42-54c878e61dc2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2ea4fca1-b781-49ec-ae42-54c878e61dc2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2ea4fca1-b781-49ec-ae42-54c878e61dc2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"user_input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"How do the pricing and capabilities of GPT-4o compare to GPT-4, and what impact does this have on the accessibility and environmental concerns of LLMs?\",\n          \"How have the advancements in Llama 3.2 models and the environmental impact of LLMs been addressed in recent AI developments?\",\n          \"What advancements has OpenAI made in the field of large language models, and how do they compare to other organizations' models in 2024?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retrieved_contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference_contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"The pricing and capabilities of GPT-4o are significantly more favorable compared to GPT-4. Specifically, GPT-4o is priced at $2.50 per million tokens, which is 12 times cheaper than GPT-4, while GPT-4o mini is available for $0.15 per million tokens, making it nearly 7 times cheaper than GPT-3.5. This dramatic reduction in cost enhances accessibility for users who may not have been able to afford the more expensive models.\\n\\nThe competitive landscape contributes to these price reductions, with other providers like Anthropic and Google offering even lower pricing for their models, further widening the accessibility gap. For instance, Anthropic's Claude 3 Haiku costs $0.25/mTok, while Google's Gemini models are priced as low as $0.0375/mTok.\\n\\nThese price drops are also linked to increased efficiency in running the models, which addresses environmental concerns related to the energy consumption of large language models (LLMs). As models become cheaper and more energy-efficient, the environmental impact of using LLMs is likely to lessen, making them more sustainable.\\n\\nOverall, the affordability and improved capabilities of newer models like GPT-4o promote broader access to advanced AI tools, while also potentially reducing their environmental footprint.\",\n          \"Recent advancements in Llama 3.2 models and the environmental impact of large language models (LLMs) have been notable in the field of AI. Meta's Llama 3.2 includes multi-modal capabilities, allowing it to process and generate not just text, but also images, audio, and video. This progression reflects a broader trend in 2024 where almost all major model vendors have released multi-modal models, showcasing significant innovation in how LLMs can be applied.\\n\\nThe careful design of training data has become crucial in creating effective models. Instead of indiscriminately scraping large amounts of data from the web, developers are focusing on generating high-quality training data, as seen with Meta's use of over 25 million synthetically generated examples for Llama 3.3.\\n\\nRegarding environmental impact, the training costs associated with LLMs, which include hardware and electricity, have decreased from millions of dollars to tens of thousands. For instance, Microsoft's Phi-2 was trained in 14 days on 96 A100 GPUs, costing around $35,000. This trend indicates a potential reduction in the energy consumption associated with training large models, although the initial costs remain significant.\\n\\nOverall, while the advancements in multi-modal capabilities represent a leap forward in LLM functionality, there remains an ongoing challenge regarding the environmental impact of training such large models. The focus on efficient training data and the decrease in costs may help mitigate some of these environmental concerns in the future.\",\n          \"In 2024, OpenAI has made significant advancements in the field of large language models (LLMs) with the introduction of their o1 models, which include o1-preview and o1-mini, released on September 12th. These models build on the concept of chain-of-thought prompting, where the model is designed to \\\"think out loud\\\" about problems, integrating this reasoning process directly into its structure. This method improves the model's ability to solve problems, providing outputs that are often better than what it could achieve without this reasoning process.\\n\\nDespite these advancements, OpenAI's GPT-4, released in March 2023, remains the benchmark for LLMs, with no other model surpassing it as of late 2024. Although several organizations, including Google and Mistral, are working on models that claim to challenge GPT-4, none have yet demonstrated superior performance.\\n\\nIn comparison, other organizations have also released competitive models. For instance, Google's Gemini-2.0 was launched on December 19, 2023, and Alibaba introduced their QwQ model on November 28, 2023, followed by a vision reasoning model called QvQ on December 24, 2023. DeepSeek's model, DeepSeek-R1-Lite-Preview, became available on November 20, 2023. While many models have emerged, the advancements made by OpenAI, particularly with the o1 models, highlight their ongoing leadership in the field, despite the growing competition from other organizations.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"GPT-4o is significantly cheaper than GPT-4, with a cost of $2.50, which is 12 times cheaper than GPT-4. Additionally, GPT-4o mini is priced at $0.15 per million tokens, making it nearly 7 times cheaper than GPT-3.5. This reduction in price is attributed to increased competition and efficiency, which also addresses environmental concerns by reducing the energy cost of running prompts. The lower pricing and increased capabilities of GPT-4o make it more accessible to users, although the era of free access to the best models has ended with the introduction of subscription services like ChatGPT Pro.\",\n          \"Recent advancements in Llama 3.2 models have demonstrated significant improvements in efficiency and capability, particularly with their ability to run on smaller devices like iPhones using the MLC Chat iOS app. These models, despite their smaller size of 1B and 3B, perform impressively well, showcasing the potential for high performance in compact models. This development is part of a broader trend in the AI industry towards increasing model efficiency, which has also contributed to a reduction in the environmental impact of running large language models (LLMs). While the environmental impact initially worsened, improvements in training and inference performance have led to more sustainable practices. The focus on efficiency has not only reduced costs but also mitigated some of the environmental concerns associated with LLMs.\",\n          \"In 2024, OpenAI's GPT-4 model, which was once the leading large language model, has been surpassed by models from 18 different organizations on the Chatbot Arena Leaderboard. These organizations include Google, Alibaba, Anthropic, Meta, and others. The advancements in large language models have been significant, with models now capable of handling much longer input contexts, such as Google's Gemini 1.5 Pro, which can accept up to 2 million tokens and input video. This has expanded the scope of problems that can be solved with LLMs. Despite the competition, OpenAI remains a key player in the field, although the achievement of surpassing GPT-4 is no longer as notable as it was in 2023.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"synthesizer_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"single_hop_specifc_query_synthesizer\",\n          \"multi_hop_abstract_query_synthesizer\",\n          \"multi_hop_specific_query_synthesizer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.to_pandas().to_csv('ragas_data_2_with response.csv')"
      ],
      "metadata": {
        "id": "i8ZEclOmUCtg"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TULcXSm0AUe0"
      },
      "source": [
        "Then we can convert that table into a `EvaluationDataset` which will make the process of evaluation smoother."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "B8zQhKR7yn1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07e874d1-9776-4a0a-9e62-07b7ac1c3809"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EvaluationDataset(features=['user_input', 'retrieved_contexts', 'reference_contexts', 'response', 'reference'], len=12)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "from ragas import EvaluationDataset\n",
        "\n",
        "evaluation_dataset = EvaluationDataset.from_pandas(dataset.to_pandas())\n",
        "evaluation_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQibuzfZAbvA"
      },
      "source": [
        "We'll need to select a judge model - in this case we're using the same model that was used to generate our Synthetic Data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "_q3Zl7sazFYB"
      },
      "outputs": [],
      "source": [
        "from ragas import evaluate\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "\n",
        "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzHuOZgBAoUU"
      },
      "source": [
        "Next up - we simply evaluate on our desired metrics!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520,
          "referenced_widgets": [
            "b3aaf433ef94428c9fe4435777f21ad3",
            "21decbb1ed234b50a15ca317da804252",
            "b2bc6ffb19a24df28605a05cc6bd4d70",
            "52d51d531ffd4bb38b905a92eb9ab9f1",
            "959dd7ebf9554086975b1de7e35f09db",
            "eaa622189dab43deac89985ad8663f53",
            "b9a6e5abcfed4cff85d598e031e29d08",
            "be7c52d2cef74dc3bddc299bbbc0507a",
            "201696f69a7042b9a78e4e1071349e8b",
            "ccfac9a890cb4b8f81b027b236d71e68",
            "361d10784ede44baad334e340b95b483"
          ]
        },
        "id": "M6mw2AeKziF1",
        "outputId": "9308d0ee-e02f-4c94-844c-5685abb617c9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3aaf433ef94428c9fe4435777f21ad3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/72 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:ragas.executor:Exception raised in Job[24]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29272, Requested 2315. Please try again in 3.174s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[1]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 28955, Requested 2442. Please try again in 2.794s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[7]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29681, Requested 2003. Please try again in 3.368s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[13]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29407, Requested 2081. Please try again in 2.976s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[5]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29055, Requested 1484. Please try again in 1.078s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[19]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29252, Requested 2237. Please try again in 2.978s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[28]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29257, Requested 1765. Please try again in 2.044s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[30]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29114, Requested 2382. Please try again in 2.992s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[25]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29246, Requested 2498. Please try again in 3.488s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[31]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29465, Requested 2782. Please try again in 4.494s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[42]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 28094, Requested 2350. Please try again in 888ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[37]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 28483, Requested 2347. Please try again in 1.66s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[29]: TimeoutError()\n",
            "ERROR:ragas.executor:Exception raised in Job[46]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29142, Requested 1857. Please try again in 1.998s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[40]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29640, Requested 1758. Please try again in 2.796s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[49]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29330, Requested 2586. Please try again in 3.832s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[43]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 28462, Requested 3015. Please try again in 2.954s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[35]: TimeoutError()\n",
            "ERROR:ragas.executor:Exception raised in Job[55]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29583, Requested 2439. Please try again in 4.044s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[41]: TimeoutError()\n",
            "ERROR:ragas.executor:Exception raised in Job[47]: TimeoutError()\n",
            "ERROR:ragas.executor:Exception raised in Job[53]: TimeoutError()\n",
            "ERROR:ragas.executor:Exception raised in Job[59]: TimeoutError()\n",
            "ERROR:ragas.executor:Exception raised in Job[71]: TimeoutError()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context_recall': 0.6495, 'faithfulness': 0.6651, 'factual_correctness': 0.5242, 'answer_relevancy': 0.9525, 'context_entity_recall': 0.3639, 'noise_sensitivity_relevant': 0.1310}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n",
        "from ragas import evaluate, RunConfig\n",
        "\n",
        "custom_run_config = RunConfig(timeout=360)\n",
        "\n",
        "result = evaluate(\n",
        "    dataset=evaluation_dataset,\n",
        "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()],\n",
        "    llm=evaluator_llm,\n",
        "    run_config=custom_run_config\n",
        ")\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df = result.to_pandas()\n",
        "result_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "omb73_5IYnGc",
        "outputId": "0f330761-fca6-4de9-f424-9429ed5f1e9e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           user_input  \\\n",
              "0   What advancements has OpenAI made in the field...   \n",
              "1     Wht is Anthropic's cheepest model and its cost?   \n",
              "2   What was the initial challenge with OpenAI's W...   \n",
              "3   What does it mean when someone says a prompt w...   \n",
              "4   How has the increased energy efficiency of AI ...   \n",
              "5   How do the criticisms of LLMs, particularly re...   \n",
              "6   How has the concept of universal access to AI ...   \n",
              "7   Why LLMs need better criticism and what are th...   \n",
              "8   How does the Claude 3.5 Sonnet compare to othe...   \n",
              "9   How have the advancements in Llama 3.2 models ...   \n",
              "10  How do the pricing and capabilities of GPT-4o ...   \n",
              "11  In light of the advancements in Large Language...   \n",
              "\n",
              "                                   retrieved_contexts  \\\n",
              "0   [OpenAI are not the only game in town here. Go...   \n",
              "1   [Today $30/mTok gets you OpenAIs most expensi...   \n",
              "2   [Did you know ChatGPT has two entirely differe...   \n",
              "3   [Its become abundantly clear over the course ...   \n",
              "4   [The much bigger problem here is the enormous ...   \n",
              "5   [LLMs need better criticism\\n\\nA lot of people...   \n",
              "6   [In 2024, almost every significant model vendo...   \n",
              "7   [LLMs need better criticism\\n\\nA lot of people...   \n",
              "8   [Getting back to models that beat GPT-4: Anthr...   \n",
              "9   [Another common technique is to use larger mod...   \n",
              "10  [Today $30/mTok gets you OpenAIs most expensi...   \n",
              "11  [Since then, almost every major LLM (and most ...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [Prompt driven app generation is a commodity a...   \n",
              "1   [gets you OpenAIs most expensive model, o1. G...   \n",
              "2   [feed with the model and talk about what you c...   \n",
              "3   [dependent on AGI itself. A model thats robus...   \n",
              "4   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "5   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "6   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "7   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "8   [<1-hop>\\n\\nthat. DeepSeek v3 is a huge 685B p...   \n",
              "9   [<1-hop>\\n\\neasy to follow. The rest of the do...   \n",
              "10  [<1-hop>\\n\\nfeed with the model and talk about...   \n",
              "11  [<1-hop>\\n\\nSimon Willisons Weblog Subscribe ...   \n",
              "\n",
              "                                             response  \\\n",
              "0   In 2024, OpenAI has made significant advanceme...   \n",
              "1   Anthropic's cheapest model is Claude 3 Haiku, ...   \n",
              "2   The initial challenge with OpenAI's WebSocket ...   \n",
              "3   When someone says a prompt without evals is li...   \n",
              "4   The increased energy efficiency of AI models h...   \n",
              "5   The criticisms of LLMs, particularly regarding...   \n",
              "6   In 2024, the concept of universal access to AI...   \n",
              "7   LLMs (Large Language Models) need better criti...   \n",
              "8   The Claude 3.5 Sonnet model is noted for its a...   \n",
              "9   Recent advancements in Llama 3.2 models and th...   \n",
              "10  The pricing and capabilities of GPT-4o are sig...   \n",
              "11  The advancements in Large Language Models (LLM...   \n",
              "\n",
              "                                            reference  context_recall  \\\n",
              "0   In 2024, OpenAI's GPT-4 model, which was once ...        0.000000   \n",
              "1   Anthropics cheapest model is Claude 3 Haiku, ...        1.000000   \n",
              "2   OpenAI started with a WebSocket API that was q...        1.000000   \n",
              "3   A prompt without the evals, models, and especi...        1.000000   \n",
              "4   The increased energy efficiency of AI models h...             NaN   \n",
              "5   The criticisms of LLMs, especially concerning ...             NaN   \n",
              "6   In 2024, the concept of universal access to AI...        0.428571   \n",
              "7   LLMs need better criticism because there are s...             NaN   \n",
              "8   Claude 3.5 Sonnet is benchmarked alongside oth...        0.666667   \n",
              "9   Recent advancements in Llama 3.2 models have d...        0.000000   \n",
              "10  GPT-4o is significantly cheaper than GPT-4, wi...        0.750000   \n",
              "11  Throughout 2024, significant advancements in L...        1.000000   \n",
              "\n",
              "    faithfulness  factual_correctness  answer_relevancy  \\\n",
              "0            NaN                 0.15          0.966099   \n",
              "1            NaN                 1.00          0.945477   \n",
              "2            NaN                 0.50          1.000000   \n",
              "3            NaN                 0.71          1.000000   \n",
              "4            NaN                 0.59          0.945216   \n",
              "5            NaN                 0.37          0.913569   \n",
              "6            NaN                 0.17          0.960220   \n",
              "7            NaN                 0.50          0.909795   \n",
              "8            NaN                 0.53          0.945543   \n",
              "9            NaN                 0.36          0.953485   \n",
              "10      0.523810                 0.71          0.938222   \n",
              "11      0.806452                 0.70          0.952405   \n",
              "\n",
              "    context_entity_recall  noise_sensitivity_relevant  \n",
              "0                0.583333                         NaN  \n",
              "1                0.666667                    0.000000  \n",
              "2                1.000000                    0.333333  \n",
              "3                0.000000                    0.000000  \n",
              "4                     NaN                         NaN  \n",
              "5                0.083333                         NaN  \n",
              "6                     NaN                         NaN  \n",
              "7                     NaN                         NaN  \n",
              "8                0.300000                         NaN  \n",
              "9                0.000000                         NaN  \n",
              "10               0.454545                    0.190476  \n",
              "11               0.187500                         NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c0b5790-2d63-4f71-97da-ad854a97218d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>retrieved_contexts</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>response</th>\n",
              "      <th>reference</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>factual_correctness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_entity_recall</th>\n",
              "      <th>noise_sensitivity_relevant</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What advancements has OpenAI made in the field...</td>\n",
              "      <td>[OpenAI are not the only game in town here. Go...</td>\n",
              "      <td>[Prompt driven app generation is a commodity a...</td>\n",
              "      <td>In 2024, OpenAI has made significant advanceme...</td>\n",
              "      <td>In 2024, OpenAI's GPT-4 model, which was once ...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.966099</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wht is Anthropic's cheepest model and its cost?</td>\n",
              "      <td>[Today $30/mTok gets you OpenAIs most expensi...</td>\n",
              "      <td>[gets you OpenAIs most expensive model, o1. G...</td>\n",
              "      <td>Anthropic's cheapest model is Claude 3 Haiku, ...</td>\n",
              "      <td>Anthropics cheapest model is Claude 3 Haiku, ...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.945477</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What was the initial challenge with OpenAI's W...</td>\n",
              "      <td>[Did you know ChatGPT has two entirely differe...</td>\n",
              "      <td>[feed with the model and talk about what you c...</td>\n",
              "      <td>The initial challenge with OpenAI's WebSocket ...</td>\n",
              "      <td>OpenAI started with a WebSocket API that was q...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What does it mean when someone says a prompt w...</td>\n",
              "      <td>[Its become abundantly clear over the course ...</td>\n",
              "      <td>[dependent on AGI itself. A model thats robus...</td>\n",
              "      <td>When someone says a prompt without evals is li...</td>\n",
              "      <td>A prompt without the evals, models, and especi...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.71</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How has the increased energy efficiency of AI ...</td>\n",
              "      <td>[The much bigger problem here is the enormous ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>The increased energy efficiency of AI models h...</td>\n",
              "      <td>The increased energy efficiency of AI models h...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.945216</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How do the criticisms of LLMs, particularly re...</td>\n",
              "      <td>[LLMs need better criticism\\n\\nA lot of people...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>The criticisms of LLMs, particularly regarding...</td>\n",
              "      <td>The criticisms of LLMs, especially concerning ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.913569</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How has the concept of universal access to AI ...</td>\n",
              "      <td>[In 2024, almost every significant model vendo...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>In 2024, the concept of universal access to AI...</td>\n",
              "      <td>In 2024, the concept of universal access to AI...</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.960220</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Why LLMs need better criticism and what are th...</td>\n",
              "      <td>[LLMs need better criticism\\n\\nA lot of people...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>LLMs (Large Language Models) need better criti...</td>\n",
              "      <td>LLMs need better criticism because there are s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.909795</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How does the Claude 3.5 Sonnet compare to othe...</td>\n",
              "      <td>[Getting back to models that beat GPT-4: Anthr...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nthat. DeepSeek v3 is a huge 685B p...</td>\n",
              "      <td>The Claude 3.5 Sonnet model is noted for its a...</td>\n",
              "      <td>Claude 3.5 Sonnet is benchmarked alongside oth...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.945543</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How have the advancements in Llama 3.2 models ...</td>\n",
              "      <td>[Another common technique is to use larger mod...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\neasy to follow. The rest of the do...</td>\n",
              "      <td>Recent advancements in Llama 3.2 models and th...</td>\n",
              "      <td>Recent advancements in Llama 3.2 models have d...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.953485</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How do the pricing and capabilities of GPT-4o ...</td>\n",
              "      <td>[Today $30/mTok gets you OpenAIs most expensi...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nfeed with the model and talk about...</td>\n",
              "      <td>The pricing and capabilities of GPT-4o are sig...</td>\n",
              "      <td>GPT-4o is significantly cheaper than GPT-4, wi...</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.523810</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.938222</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.190476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>In light of the advancements in Large Language...</td>\n",
              "      <td>[Since then, almost every major LLM (and most ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nSimon Willisons Weblog Subscribe ...</td>\n",
              "      <td>The advancements in Large Language Models (LLM...</td>\n",
              "      <td>Throughout 2024, significant advancements in L...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.806452</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.952405</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c0b5790-2d63-4f71-97da-ad854a97218d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2c0b5790-2d63-4f71-97da-ad854a97218d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2c0b5790-2d63-4f71-97da-ad854a97218d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-546b73a1-b888-455d-9e31-918b1222d712\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-546b73a1-b888-455d-9e31-918b1222d712')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-546b73a1-b888-455d-9e31-918b1222d712 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_31c843a8-ee9e-4914-b001-a67861a98001\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_31c843a8-ee9e-4914-b001-a67861a98001 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('result_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result_df",
              "summary": "{\n  \"name\": \"result_df\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"user_input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"How do the pricing and capabilities of GPT-4o compare to GPT-4, and what impact does this have on the accessibility and environmental concerns of LLMs?\",\n          \"How have the advancements in Llama 3.2 models and the environmental impact of LLMs been addressed in recent AI developments?\",\n          \"What advancements has OpenAI made in the field of large language models, and how do they compare to other organizations' models in 2024?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retrieved_contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference_contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"The pricing and capabilities of GPT-4o are significantly more favorable compared to GPT-4. Specifically, GPT-4o is priced at $2.50 per million tokens, which is 12 times cheaper than GPT-4, while GPT-4o mini is available for $0.15 per million tokens, making it nearly 7 times cheaper than GPT-3.5. This dramatic reduction in cost enhances accessibility for users who may not have been able to afford the more expensive models.\\n\\nThe competitive landscape contributes to these price reductions, with other providers like Anthropic and Google offering even lower pricing for their models, further widening the accessibility gap. For instance, Anthropic's Claude 3 Haiku costs $0.25/mTok, while Google's Gemini models are priced as low as $0.0375/mTok.\\n\\nThese price drops are also linked to increased efficiency in running the models, which addresses environmental concerns related to the energy consumption of large language models (LLMs). As models become cheaper and more energy-efficient, the environmental impact of using LLMs is likely to lessen, making them more sustainable.\\n\\nOverall, the affordability and improved capabilities of newer models like GPT-4o promote broader access to advanced AI tools, while also potentially reducing their environmental footprint.\",\n          \"Recent advancements in Llama 3.2 models and the environmental impact of large language models (LLMs) have been notable in the field of AI. Meta's Llama 3.2 includes multi-modal capabilities, allowing it to process and generate not just text, but also images, audio, and video. This progression reflects a broader trend in 2024 where almost all major model vendors have released multi-modal models, showcasing significant innovation in how LLMs can be applied.\\n\\nThe careful design of training data has become crucial in creating effective models. Instead of indiscriminately scraping large amounts of data from the web, developers are focusing on generating high-quality training data, as seen with Meta's use of over 25 million synthetically generated examples for Llama 3.3.\\n\\nRegarding environmental impact, the training costs associated with LLMs, which include hardware and electricity, have decreased from millions of dollars to tens of thousands. For instance, Microsoft's Phi-2 was trained in 14 days on 96 A100 GPUs, costing around $35,000. This trend indicates a potential reduction in the energy consumption associated with training large models, although the initial costs remain significant.\\n\\nOverall, while the advancements in multi-modal capabilities represent a leap forward in LLM functionality, there remains an ongoing challenge regarding the environmental impact of training such large models. The focus on efficient training data and the decrease in costs may help mitigate some of these environmental concerns in the future.\",\n          \"In 2024, OpenAI has made significant advancements in the field of large language models (LLMs) with the introduction of their o1 models, which include o1-preview and o1-mini, released on September 12th. These models build on the concept of chain-of-thought prompting, where the model is designed to \\\"think out loud\\\" about problems, integrating this reasoning process directly into its structure. This method improves the model's ability to solve problems, providing outputs that are often better than what it could achieve without this reasoning process.\\n\\nDespite these advancements, OpenAI's GPT-4, released in March 2023, remains the benchmark for LLMs, with no other model surpassing it as of late 2024. Although several organizations, including Google and Mistral, are working on models that claim to challenge GPT-4, none have yet demonstrated superior performance.\\n\\nIn comparison, other organizations have also released competitive models. For instance, Google's Gemini-2.0 was launched on December 19, 2023, and Alibaba introduced their QwQ model on November 28, 2023, followed by a vision reasoning model called QvQ on December 24, 2023. DeepSeek's model, DeepSeek-R1-Lite-Preview, became available on November 20, 2023. While many models have emerged, the advancements made by OpenAI, particularly with the o1 models, highlight their ongoing leadership in the field, despite the growing competition from other organizations.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"GPT-4o is significantly cheaper than GPT-4, with a cost of $2.50, which is 12 times cheaper than GPT-4. Additionally, GPT-4o mini is priced at $0.15 per million tokens, making it nearly 7 times cheaper than GPT-3.5. This reduction in price is attributed to increased competition and efficiency, which also addresses environmental concerns by reducing the energy cost of running prompts. The lower pricing and increased capabilities of GPT-4o make it more accessible to users, although the era of free access to the best models has ended with the introduction of subscription services like ChatGPT Pro.\",\n          \"Recent advancements in Llama 3.2 models have demonstrated significant improvements in efficiency and capability, particularly with their ability to run on smaller devices like iPhones using the MLC Chat iOS app. These models, despite their smaller size of 1B and 3B, perform impressively well, showcasing the potential for high performance in compact models. This development is part of a broader trend in the AI industry towards increasing model efficiency, which has also contributed to a reduction in the environmental impact of running large language models (LLMs). While the environmental impact initially worsened, improvements in training and inference performance have led to more sustainable practices. The focus on efficiency has not only reduced costs but also mitigated some of the environmental concerns associated with LLMs.\",\n          \"In 2024, OpenAI's GPT-4 model, which was once the leading large language model, has been surpassed by models from 18 different organizations on the Chatbot Arena Leaderboard. These organizations include Google, Alibaba, Anthropic, Meta, and others. The advancements in large language models have been significant, with models now capable of handling much longer input contexts, such as Google's Gemini 1.5 Pro, which can accept up to 2 million tokens and input video. This has expanded the scope of problems that can be solved with LLMs. Despite the competition, OpenAI remains a key player in the field, although the achievement of surpassing GPT-4 is no longer as notable as it was in 2023.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.41747842316944156,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.0,\n          0.75,\n          0.42857142857142855\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"faithfulness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19985813784688894,\n        \"min\": 0.5238095238095238,\n        \"max\": 0.8064516129032258,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8064516129032258,\n          0.5238095238095238\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"factual_correctness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24272911700581828,\n        \"min\": 0.15,\n        \"max\": 1.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.36,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_relevancy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.027719375404344847,\n        \"min\": 0.909795398896382,\n        \"max\": 0.9999999999999997,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.9382215332666196,\n          0.9534845265112973\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_entity_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.341215232401938,\n        \"min\": 0.0,\n        \"max\": 0.999999995,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.6666666644444444,\n          0.29999999969999996\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"noise_sensitivity_relevant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16206807822747726,\n        \"min\": 0.0,\n        \"max\": 0.3333333333333333,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          0.3333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZxxr2NqAyBp"
      },
      "source": [
        "## Making Adjustments and Re-Evaluating\n",
        "\n",
        "Now that we've got our baseline - let's make a change and see how the model improves or doesn't improve!\n",
        "\n",
        "> NOTE: This will be using Cohere's Rerank model (which was updated fairly [recently](https://docs.cohere.com/v2/changelog/rerank-v3.5)) - please be sure to [sign-up for an API key!](https://docs.cohere.com/reference/about)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = getpass(\"Please enter your Cohere API key!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAaY_KrllaPM",
        "outputId": "6b82ef89-d833-4cfb-fd85-55829c679b67"
      },
      "execution_count": 32,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your Cohere API key!路路路路路路路路路路\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "zMwNl2M5BYWg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c15959ad-529b-4288-eabf-aebd49aa850b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/252.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m143.4/252.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU cohere langchain_cohere"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwqpWY5Aq-6K"
      },
      "source": [
        "\n",
        "We'll first set our retriever to return more documents, which will allow us to take advantage of the reranking."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 20})"
      ],
      "metadata": {
        "id": "OhxGPdaElnLr"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9So496gOq-6L"
      },
      "source": [
        "Reranking, or contextual compression, is a technique that uses a reranker to compress the retrieved documents into a smaller set of documents.\n",
        "\n",
        "This is essentially a slower, more accurate form of semantic similarity that we use on a smaller subset of our documents."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "def retrieve_adjusted(state):\n",
        "  compressor = CohereRerank(model=\"rerank-v3.5\")\n",
        "  compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=retriever, search_kwargs={\"k\": 5}\n",
        "  )\n",
        "  retrieved_docs = compression_retriever.invoke(state[\"question\"])\n",
        "  return {\"context\" : retrieved_docs}"
      ],
      "metadata": {
        "id": "XmMiwmnUlutr"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1zb8KgZq-6L"
      },
      "source": [
        "We can simply rebuild our graph with the new retriever!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "  question: str\n",
        "  context: List[Document]\n",
        "  response: str\n",
        "\n",
        "graph_builder = StateGraph(State).add_sequence([retrieve_adjusted, generate])\n",
        "graph_builder.add_edge(START, \"retrieve_adjusted\")\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "kdZihTsemF5-"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = graph.invoke({\"question\" : \"How are LLM agents useful?\"})\n",
        "response[\"response\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "c2aBOOramKsh",
        "outputId": "8f7a084d-3004-4376-d963-8bf2416cb0f5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LLM agents are considered useful primarily for their capability in writing code, as they can effectively handle programming languages with simpler grammar rules compared to natural languages. However, there is skepticism regarding their overall utility due to their inherent gullibility; they cannot reliably distinguish truth from fiction, which poses challenges for tasks that require meaningful decision-making. The excitement around AI agents, which are often described as systems that can operate on behalf of users, has not yet translated into widespread, practical applications. Many remain concerned about the potential negative impacts of LLMs, such as environmental concerns, ethical issues related to training data, and the reliability of the outputs. Thus, while LLMs have their strengths, especially in coding, there are significant reservations about their broader usefulness and the need for critical evaluation of the technology.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "for test_row in dataset:\n",
        "  test_row.eval_sample.response = np.nan\n",
        "  test_row.eval_sample.retrieved_contexts = np.nan\n",
        "dataset.to_pandas()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "nMEBLa2anW8h",
        "outputId": "7a1fd5aa-7bdf-4924-f114-dca2a14358f2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pydantic/main.py:426: UserWarning: Pydantic serializer warnings:\n",
            "  Expected `list[str]` but got `float` with value `nan` - serialized value may not be as expected\n",
            "  Expected `str` but got `float` with value `nan` - serialized value may not be as expected\n",
            "  return self.__pydantic_serializer__.to_python(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           user_input  retrieved_contexts  \\\n",
              "0   What advancements has OpenAI made in the field...                 NaN   \n",
              "1     Wht is Anthropic's cheepest model and its cost?                 NaN   \n",
              "2   What was the initial challenge with OpenAI's W...                 NaN   \n",
              "3   What does it mean when someone says a prompt w...                 NaN   \n",
              "4   How has the increased energy efficiency of AI ...                 NaN   \n",
              "5   How do the criticisms of LLMs, particularly re...                 NaN   \n",
              "6   How has the concept of universal access to AI ...                 NaN   \n",
              "7   Why LLMs need better criticism and what are th...                 NaN   \n",
              "8   How does the Claude 3.5 Sonnet compare to othe...                 NaN   \n",
              "9   How have the advancements in Llama 3.2 models ...                 NaN   \n",
              "10  How do the pricing and capabilities of GPT-4o ...                 NaN   \n",
              "11  In light of the advancements in Large Language...                 NaN   \n",
              "\n",
              "                                   reference_contexts  response  \\\n",
              "0   [Prompt driven app generation is a commodity a...       NaN   \n",
              "1   [gets you OpenAIs most expensive model, o1. G...       NaN   \n",
              "2   [feed with the model and talk about what you c...       NaN   \n",
              "3   [dependent on AGI itself. A model thats robus...       NaN   \n",
              "4   [<1-hop>\\n\\nPrompt driven app generation is a ...       NaN   \n",
              "5   [<1-hop>\\n\\nPrompt driven app generation is a ...       NaN   \n",
              "6   [<1-hop>\\n\\nPrompt driven app generation is a ...       NaN   \n",
              "7   [<1-hop>\\n\\nPrompt driven app generation is a ...       NaN   \n",
              "8   [<1-hop>\\n\\nthat. DeepSeek v3 is a huge 685B p...       NaN   \n",
              "9   [<1-hop>\\n\\neasy to follow. The rest of the do...       NaN   \n",
              "10  [<1-hop>\\n\\nfeed with the model and talk about...       NaN   \n",
              "11  [<1-hop>\\n\\nSimon Willisons Weblog Subscribe ...       NaN   \n",
              "\n",
              "                                            reference  \\\n",
              "0   In 2024, OpenAI's GPT-4 model, which was once ...   \n",
              "1   Anthropics cheapest model is Claude 3 Haiku, ...   \n",
              "2   OpenAI started with a WebSocket API that was q...   \n",
              "3   A prompt without the evals, models, and especi...   \n",
              "4   The increased energy efficiency of AI models h...   \n",
              "5   The criticisms of LLMs, especially concerning ...   \n",
              "6   In 2024, the concept of universal access to AI...   \n",
              "7   LLMs need better criticism because there are s...   \n",
              "8   Claude 3.5 Sonnet is benchmarked alongside oth...   \n",
              "9   Recent advancements in Llama 3.2 models have d...   \n",
              "10  GPT-4o is significantly cheaper than GPT-4, wi...   \n",
              "11  Throughout 2024, significant advancements in L...   \n",
              "\n",
              "                        synthesizer_name  \n",
              "0   single_hop_specifc_query_synthesizer  \n",
              "1   single_hop_specifc_query_synthesizer  \n",
              "2   single_hop_specifc_query_synthesizer  \n",
              "3   single_hop_specifc_query_synthesizer  \n",
              "4   multi_hop_abstract_query_synthesizer  \n",
              "5   multi_hop_abstract_query_synthesizer  \n",
              "6   multi_hop_abstract_query_synthesizer  \n",
              "7   multi_hop_abstract_query_synthesizer  \n",
              "8   multi_hop_specific_query_synthesizer  \n",
              "9   multi_hop_specific_query_synthesizer  \n",
              "10  multi_hop_specific_query_synthesizer  \n",
              "11  multi_hop_specific_query_synthesizer  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9e77dba-09eb-4797-8658-c37ad26f1608\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>retrieved_contexts</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>response</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What advancements has OpenAI made in the field...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Prompt driven app generation is a commodity a...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>In 2024, OpenAI's GPT-4 model, which was once ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wht is Anthropic's cheepest model and its cost?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[gets you OpenAIs most expensive model, o1. G...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Anthropics cheapest model is Claude 3 Haiku, ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What was the initial challenge with OpenAI's W...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[feed with the model and talk about what you c...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OpenAI started with a WebSocket API that was q...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What does it mean when someone says a prompt w...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[dependent on AGI itself. A model thats robus...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A prompt without the evals, models, and especi...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How has the increased energy efficiency of AI ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The increased energy efficiency of AI models h...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How do the criticisms of LLMs, particularly re...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The criticisms of LLMs, especially concerning ...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How has the concept of universal access to AI ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>In 2024, the concept of universal access to AI...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Why LLMs need better criticism and what are th...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LLMs need better criticism because there are s...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How does the Claude 3.5 Sonnet compare to othe...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nthat. DeepSeek v3 is a huge 685B p...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Claude 3.5 Sonnet is benchmarked alongside oth...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How have the advancements in Llama 3.2 models ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\neasy to follow. The rest of the do...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Recent advancements in Llama 3.2 models have d...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How do the pricing and capabilities of GPT-4o ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nfeed with the model and talk about...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>GPT-4o is significantly cheaper than GPT-4, wi...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>In light of the advancements in Large Language...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nSimon Willisons Weblog Subscribe ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Throughout 2024, significant advancements in L...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9e77dba-09eb-4797-8658-c37ad26f1608')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e9e77dba-09eb-4797-8658-c37ad26f1608 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e9e77dba-09eb-4797-8658-c37ad26f1608');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-349b3b3e-ab08-4d7e-81b1-e0594734cde3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-349b3b3e-ab08-4d7e-81b1-e0594734cde3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-349b3b3e-ab08-4d7e-81b1-e0594734cde3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"user_input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"How do the pricing and capabilities of GPT-4o compare to GPT-4, and what impact does this have on the accessibility and environmental concerns of LLMs?\",\n          \"How have the advancements in Llama 3.2 models and the environmental impact of LLMs been addressed in recent AI developments?\",\n          \"What advancements has OpenAI made in the field of large language models, and how do they compare to other organizations' models in 2024?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retrieved_contexts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference_contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"synthesizer_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "siBFKs-gCDdQ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "for test_row in dataset:\n",
        "  response = graph.invoke({\"question\" : test_row.eval_sample.user_input})\n",
        "  test_row.eval_sample.response = response[\"response\"]\n",
        "  test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]\n",
        "  time.sleep(2) # To try to avoid rate limiting."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.to_pandas()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "id": "k61zFFDZmp9F",
        "outputId": "3846c889-e254-4efb-d608-a67b1c9e449a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           user_input  \\\n",
              "0   What advancements has OpenAI made in the field...   \n",
              "1     Wht is Anthropic's cheepest model and its cost?   \n",
              "2   What was the initial challenge with OpenAI's W...   \n",
              "3   What does it mean when someone says a prompt w...   \n",
              "4   How has the increased energy efficiency of AI ...   \n",
              "5   How do the criticisms of LLMs, particularly re...   \n",
              "6   How has the concept of universal access to AI ...   \n",
              "7   Why LLMs need better criticism and what are th...   \n",
              "8   How does the Claude 3.5 Sonnet compare to othe...   \n",
              "9   How have the advancements in Llama 3.2 models ...   \n",
              "10  How do the pricing and capabilities of GPT-4o ...   \n",
              "11  In light of the advancements in Large Language...   \n",
              "\n",
              "                                   retrieved_contexts  \\\n",
              "0   [Simon Willisons Weblog\\n\\nSubscribe\\n\\nThing...   \n",
              "1   [Today $30/mTok gets you OpenAIs most expensi...   \n",
              "2   [These abilities are just a few weeks old at t...   \n",
              "3   [Its become abundantly clear over the course ...   \n",
              "4   [I think this means that, as individual users,...   \n",
              "5   [LLMs need better criticism\\n\\nA lot of people...   \n",
              "6   [Simon Willisons Weblog\\n\\nSubscribe\\n\\nThing...   \n",
              "7   [LLMs need better criticism\\n\\nA lot of people...   \n",
              "8   [Getting back to models that beat GPT-4: Anthr...   \n",
              "9   [Agents still havent really happened yet\\n\\...   \n",
              "10  [Today $30/mTok gets you OpenAIs most expensi...   \n",
              "11  [Simon Willisons Weblog\\n\\nSubscribe\\n\\nThing...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [Prompt driven app generation is a commodity a...   \n",
              "1   [gets you OpenAIs most expensive model, o1. G...   \n",
              "2   [feed with the model and talk about what you c...   \n",
              "3   [dependent on AGI itself. A model thats robus...   \n",
              "4   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "5   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "6   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "7   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "8   [<1-hop>\\n\\nthat. DeepSeek v3 is a huge 685B p...   \n",
              "9   [<1-hop>\\n\\neasy to follow. The rest of the do...   \n",
              "10  [<1-hop>\\n\\nfeed with the model and talk about...   \n",
              "11  [<1-hop>\\n\\nSimon Willisons Weblog Subscribe ...   \n",
              "\n",
              "                                             response  \\\n",
              "0   In 2024, OpenAI made significant advancements ...   \n",
              "1   Anthropic's cheapest model is Claude 3 Haiku, ...   \n",
              "2   The initial challenge with OpenAI's WebSocket ...   \n",
              "3   When someone says a prompt without evals is li...   \n",
              "4   The increased energy efficiency of AI models h...   \n",
              "5   The criticisms of large language models (LLMs)...   \n",
              "6   In 2024, the concept of universal access to AI...   \n",
              "7   LLMs (Large Language Models) need better criti...   \n",
              "8   The Claude 3.5 Sonnet model is noted for its p...   \n",
              "9   Recent advancements in Llama 3.2 models and th...   \n",
              "10  The pricing of GPT-4o is significantly lower t...   \n",
              "11  The advancements in Large Language Models (LLM...   \n",
              "\n",
              "                                            reference  \\\n",
              "0   In 2024, OpenAI's GPT-4 model, which was once ...   \n",
              "1   Anthropics cheapest model is Claude 3 Haiku, ...   \n",
              "2   OpenAI started with a WebSocket API that was q...   \n",
              "3   A prompt without the evals, models, and especi...   \n",
              "4   The increased energy efficiency of AI models h...   \n",
              "5   The criticisms of LLMs, especially concerning ...   \n",
              "6   In 2024, the concept of universal access to AI...   \n",
              "7   LLMs need better criticism because there are s...   \n",
              "8   Claude 3.5 Sonnet is benchmarked alongside oth...   \n",
              "9   Recent advancements in Llama 3.2 models have d...   \n",
              "10  GPT-4o is significantly cheaper than GPT-4, wi...   \n",
              "11  Throughout 2024, significant advancements in L...   \n",
              "\n",
              "                        synthesizer_name  \n",
              "0   single_hop_specifc_query_synthesizer  \n",
              "1   single_hop_specifc_query_synthesizer  \n",
              "2   single_hop_specifc_query_synthesizer  \n",
              "3   single_hop_specifc_query_synthesizer  \n",
              "4   multi_hop_abstract_query_synthesizer  \n",
              "5   multi_hop_abstract_query_synthesizer  \n",
              "6   multi_hop_abstract_query_synthesizer  \n",
              "7   multi_hop_abstract_query_synthesizer  \n",
              "8   multi_hop_specific_query_synthesizer  \n",
              "9   multi_hop_specific_query_synthesizer  \n",
              "10  multi_hop_specific_query_synthesizer  \n",
              "11  multi_hop_specific_query_synthesizer  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0cf4323b-de60-4971-9683-f25d1d1d0181\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>retrieved_contexts</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>response</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What advancements has OpenAI made in the field...</td>\n",
              "      <td>[Simon Willisons Weblog\\n\\nSubscribe\\n\\nThing...</td>\n",
              "      <td>[Prompt driven app generation is a commodity a...</td>\n",
              "      <td>In 2024, OpenAI made significant advancements ...</td>\n",
              "      <td>In 2024, OpenAI's GPT-4 model, which was once ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wht is Anthropic's cheepest model and its cost?</td>\n",
              "      <td>[Today $30/mTok gets you OpenAIs most expensi...</td>\n",
              "      <td>[gets you OpenAIs most expensive model, o1. G...</td>\n",
              "      <td>Anthropic's cheapest model is Claude 3 Haiku, ...</td>\n",
              "      <td>Anthropics cheapest model is Claude 3 Haiku, ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What was the initial challenge with OpenAI's W...</td>\n",
              "      <td>[These abilities are just a few weeks old at t...</td>\n",
              "      <td>[feed with the model and talk about what you c...</td>\n",
              "      <td>The initial challenge with OpenAI's WebSocket ...</td>\n",
              "      <td>OpenAI started with a WebSocket API that was q...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What does it mean when someone says a prompt w...</td>\n",
              "      <td>[Its become abundantly clear over the course ...</td>\n",
              "      <td>[dependent on AGI itself. A model thats robus...</td>\n",
              "      <td>When someone says a prompt without evals is li...</td>\n",
              "      <td>A prompt without the evals, models, and especi...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How has the increased energy efficiency of AI ...</td>\n",
              "      <td>[I think this means that, as individual users,...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>The increased energy efficiency of AI models h...</td>\n",
              "      <td>The increased energy efficiency of AI models h...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How do the criticisms of LLMs, particularly re...</td>\n",
              "      <td>[LLMs need better criticism\\n\\nA lot of people...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>The criticisms of large language models (LLMs)...</td>\n",
              "      <td>The criticisms of LLMs, especially concerning ...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How has the concept of universal access to AI ...</td>\n",
              "      <td>[Simon Willisons Weblog\\n\\nSubscribe\\n\\nThing...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>In 2024, the concept of universal access to AI...</td>\n",
              "      <td>In 2024, the concept of universal access to AI...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Why LLMs need better criticism and what are th...</td>\n",
              "      <td>[LLMs need better criticism\\n\\nA lot of people...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>LLMs (Large Language Models) need better criti...</td>\n",
              "      <td>LLMs need better criticism because there are s...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How does the Claude 3.5 Sonnet compare to othe...</td>\n",
              "      <td>[Getting back to models that beat GPT-4: Anthr...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nthat. DeepSeek v3 is a huge 685B p...</td>\n",
              "      <td>The Claude 3.5 Sonnet model is noted for its p...</td>\n",
              "      <td>Claude 3.5 Sonnet is benchmarked alongside oth...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How have the advancements in Llama 3.2 models ...</td>\n",
              "      <td>[Agents still havent really happened yet\\n\\...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\neasy to follow. The rest of the do...</td>\n",
              "      <td>Recent advancements in Llama 3.2 models and th...</td>\n",
              "      <td>Recent advancements in Llama 3.2 models have d...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How do the pricing and capabilities of GPT-4o ...</td>\n",
              "      <td>[Today $30/mTok gets you OpenAIs most expensi...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nfeed with the model and talk about...</td>\n",
              "      <td>The pricing of GPT-4o is significantly lower t...</td>\n",
              "      <td>GPT-4o is significantly cheaper than GPT-4, wi...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>In light of the advancements in Large Language...</td>\n",
              "      <td>[Simon Willisons Weblog\\n\\nSubscribe\\n\\nThing...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nSimon Willisons Weblog Subscribe ...</td>\n",
              "      <td>The advancements in Large Language Models (LLM...</td>\n",
              "      <td>Throughout 2024, significant advancements in L...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cf4323b-de60-4971-9683-f25d1d1d0181')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0cf4323b-de60-4971-9683-f25d1d1d0181 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0cf4323b-de60-4971-9683-f25d1d1d0181');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a548b009-ea51-431a-8e6d-2f8ef39fa5e4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a548b009-ea51-431a-8e6d-2f8ef39fa5e4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a548b009-ea51-431a-8e6d-2f8ef39fa5e4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"user_input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"How do the pricing and capabilities of GPT-4o compare to GPT-4, and what impact does this have on the accessibility and environmental concerns of LLMs?\",\n          \"How have the advancements in Llama 3.2 models and the environmental impact of LLMs been addressed in recent AI developments?\",\n          \"What advancements has OpenAI made in the field of large language models, and how do they compare to other organizations' models in 2024?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retrieved_contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference_contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"The pricing of GPT-4o is significantly lower than that of GPT-4, costing $2.50 per million tokens, which is 12 times cheaper than GPT-4's $30 per million tokens. Additionally, GPT-4o mini is priced at $0.15 per million tokens, making it nearly 7 times cheaper than GPT-3.5. This trend of decreasing prices is also seen with other model providers, such as Anthropic and Google, which offer even lower rates, with Google's Gemini 1.5 Flash at $0.075 per million tokens and Gemini 1.5 Flash 8B at $0.0375 per million tokens.\\n\\nThese price reductions are attributed to increased competition among providers and enhanced efficiency in model performance. The efficiency improvements are particularly relevant for those concerned about the environmental impact of large language models (LLMs), as they correlate directly with the energy consumption required to run these models. Lower costs imply that the operational energy usage per prompt is reduced, which can mitigate environmental concerns associated with LLMs.\\n\\nOverall, the combination of reduced pricing and improved capabilities not only makes advanced LLMs more accessible to a wider audience but also addresses some of the environmental issues related to their usage.\",\n          \"Recent advancements in Llama 3.2 models and the environmental impact of large language models (LLMs) have been notable in recent AI developments. \\n\\nFirstly, the Llama 3.2 models have demonstrated significant improvements in training efficiency. For example, while the Llama 3.1 model required 30,840,000 GPU hours for training, the DeepSeek v3 model was trained using only 2,788,000 GPU hours at an estimated cost of about $5.6 million, showcasing a more effective use of resources. This increased efficiency has contributed to a reduction in the energy usage and environmental impact associated with running LLMs, marking a positive trend in this area.\\n\\nFurthermore, it has been reported that the environmental impact of LLMs has improved significantly over the past couple of years. The advancements in model efficiency have allowed for a decrease in the energy consumption required for prompts. OpenAI has also reduced the cost of prompts by 100 times compared to the GPT-3 era, indicating a broader trend toward more sustainable practices within the industry.\\n\\nOverall, these developments reflect a dual focus on enhancing model performance while also addressing the environmental footprint of LLMs, indicating progress in both technological and ecological aspects of AI.\",\n          \"In 2024, OpenAI made significant advancements in the field of large language models (LLMs) with the introduction of their new o1 models, which were initially released as o1-preview and o1-mini. These models build upon the concept of chain-of-thought prompting, incorporating reasoning processes directly into the model. This allows the o1 models to effectively \\\"think through\\\" problems using \\\"reasoning tokens,\\\" which enhances their problem-solving capabilities compared to previous models.\\n\\nAdditionally, the overall landscape of LLMs saw a substantial reduction in prices due to increased efficiency and competition, making advanced models more accessible. Furthermore, the year marked a trend towards multimodal capabilities, with vision becoming common and audio and video functionalities starting to emerge.\\n\\nIn terms of comparison with other organizations' models in 2024, OpenAI's advancements, particularly with the o1 models, positioned them at the forefront of LLM development. The context suggests that while other organizations were making strides, OpenAI's innovations, especially in reasoning capabilities, were noteworthy. However, it is also mentioned that the best currently available LLM was trained in China for significantly less cost, indicating that other organizations were still competitive in some areas. Overall, OpenAI remained a leader in the field, breaking previous barriers and enhancing the functionality of their models.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"GPT-4o is significantly cheaper than GPT-4, with a cost of $2.50, which is 12 times cheaper than GPT-4. Additionally, GPT-4o mini is priced at $0.15 per million tokens, making it nearly 7 times cheaper than GPT-3.5. This reduction in price is attributed to increased competition and efficiency, which also addresses environmental concerns by reducing the energy cost of running prompts. The lower pricing and increased capabilities of GPT-4o make it more accessible to users, although the era of free access to the best models has ended with the introduction of subscription services like ChatGPT Pro.\",\n          \"Recent advancements in Llama 3.2 models have demonstrated significant improvements in efficiency and capability, particularly with their ability to run on smaller devices like iPhones using the MLC Chat iOS app. These models, despite their smaller size of 1B and 3B, perform impressively well, showcasing the potential for high performance in compact models. This development is part of a broader trend in the AI industry towards increasing model efficiency, which has also contributed to a reduction in the environmental impact of running large language models (LLMs). While the environmental impact initially worsened, improvements in training and inference performance have led to more sustainable practices. The focus on efficiency has not only reduced costs but also mitigated some of the environmental concerns associated with LLMs.\",\n          \"In 2024, OpenAI's GPT-4 model, which was once the leading large language model, has been surpassed by models from 18 different organizations on the Chatbot Arena Leaderboard. These organizations include Google, Alibaba, Anthropic, Meta, and others. The advancements in large language models have been significant, with models now capable of handling much longer input contexts, such as Google's Gemini 1.5 Pro, which can accept up to 2 million tokens and input video. This has expanded the scope of problems that can be solved with LLMs. Despite the competition, OpenAI remains a key player in the field, although the achievement of surpassing GPT-4 is no longer as notable as it was in 2023.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"synthesizer_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"single_hop_specifc_query_synthesizer\",\n          \"multi_hop_abstract_query_synthesizer\",\n          \"multi_hop_specific_query_synthesizer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_dataset = EvaluationDataset.from_pandas(dataset.to_pandas())"
      ],
      "metadata": {
        "id": "m74fqpqhom1I"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "b09b0c42e0364396aee593f2ba1f18a2",
            "ae2cb8aa76424c01b0e39988cba92f0a",
            "9e837089e2ed4366b518306993092ede",
            "ccc8bd831acf490bb821cbe9a4d6ce5e",
            "d7f40417bcb24600b0e562fe2be29560",
            "a06cc5c232fe415c80c3a468b29ccc66",
            "d06dd06393844bbc8e176fea19a4e142",
            "31981ef797934adebeba357626d4e287",
            "66e038d8569b43fb8adc5211537fccef",
            "ab759276b57d4de6acefd71e01bcacc6",
            "117883f62a654d6996c2f9f8464cd22b",
            "e2d866b5da0943a7bb812da3bc819658"
          ]
        },
        "id": "5jXHvoIDCeKI",
        "outputId": "90b7754d-d2b0-487f-912f-6f572e56d2e4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2d866b5da0943a7bb812da3bc819658",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/72 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[65]: TimeoutError()\n",
            "Exception raised in Job[71]: TimeoutError()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.7610, 'faithfulness': 0.8309, 'factual_correctness': 0.4275, 'answer_relevancy': 0.8605, 'context_entity_recall': 0.5109, 'noise_sensitivity_relevant': 0.3846}"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = evaluate(\n",
        "    dataset=evaluation_dataset,\n",
        "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()],\n",
        "    llm=evaluator_llm,\n",
        "    run_config=custom_run_config\n",
        ")\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result2 = evaluate(\n",
        "    dataset=evaluation_dataset,\n",
        "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()],\n",
        "    llm=evaluator_llm,\n",
        "    run_config=custom_run_config\n",
        ")\n",
        "result2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503,
          "referenced_widgets": [
            "8368a3dda89b42ebbcaa5c29a7af46a9",
            "6a72df0f04764852a2eccd4719d96447",
            "b6ecf12652c845bead91ed1850639163",
            "5ca29705e23c4191b291ba441c76c108",
            "9f824f9ca8c3455bb0840b5e2b0e7a4b",
            "b050cc565cf74497954b4cd9338152cd",
            "c641cabb4fbf4ff09a1d5615d36238b8",
            "d3f1d20338494509a53c3491b80b3317",
            "dcbb8834fd7b4ed1a830cf8257f33629",
            "8345c31700364316ae6fa13933d2f801",
            "650d3121b13744c8a381d1bd4db3e078"
          ]
        },
        "id": "zLeRDcnNotw_",
        "outputId": "b35fc99f-5f34-428c-856a-132164a41c08"
      },
      "execution_count": 42,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8368a3dda89b42ebbcaa5c29a7af46a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/72 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:ragas.executor:Exception raised in Job[24]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29031, Requested 1852. Please try again in 1.766s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[1]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29129, Requested 2045. Please try again in 2.348s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[13]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29512, Requested 1696. Please try again in 2.416s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[2]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29844, Requested 1433. Please try again in 2.554s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[19]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29539, Requested 1833. Please try again in 2.744s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[36]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29578, Requested 1895. Please try again in 2.946s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[47]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29742, Requested 1791. Please try again in 3.066s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[5]: TimeoutError()\n",
            "ERROR:ragas.executor:Exception raised in Job[26]: TimeoutError()\n",
            "ERROR:ragas.executor:Exception raised in Job[48]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29426, Requested 1859. Please try again in 2.57s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[54]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29114, Requested 1872. Please try again in 1.972s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[29]: TimeoutError()\n",
            "ERROR:ragas.executor:Exception raised in Job[43]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 28908, Requested 2506. Please try again in 2.828s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[35]: TimeoutError()\n",
            "ERROR:ragas.executor:Exception raised in Job[59]: InternalServerError(<html>\n",
            "<head><title>502 Bad Gateway</title></head>\n",
            "<body>\n",
            "<center><h1>502 Bad Gateway</h1></center>\n",
            "<hr><center>cloudflare</center>\n",
            "</body>\n",
            "</html>)\n",
            "ERROR:ragas.executor:Exception raised in Job[49]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-TUDVNCQITlowbOaFB0KsnZu8 on tokens per min (TPM): Limit 30000, Used 29510, Requested 2210. Please try again in 3.44s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[53]: TimeoutError()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context_recall': 0.7542, 'faithfulness': 0.7047, 'factual_correctness': 0.5700, 'answer_relevancy': 0.8582, 'context_entity_recall': 0.3597, 'noise_sensitivity_relevant': 0.3261}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df2 = result2.to_pandas()\n",
        "result_df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LA_dF3wen45H",
        "outputId": "49a6da9f-173c-4a34-8224-2f8bc5e28863"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           user_input  \\\n",
              "0   What advancements has OpenAI made in the field...   \n",
              "1     Wht is Anthropic's cheepest model and its cost?   \n",
              "2   What was the initial challenge with OpenAI's W...   \n",
              "3   What does it mean when someone says a prompt w...   \n",
              "4   How has the increased energy efficiency of AI ...   \n",
              "5   How do the criticisms of LLMs, particularly re...   \n",
              "6   How has the concept of universal access to AI ...   \n",
              "7   Why LLMs need better criticism and what are th...   \n",
              "8   How does the Claude 3.5 Sonnet compare to othe...   \n",
              "9   How have the advancements in Llama 3.2 models ...   \n",
              "10  How do the pricing and capabilities of GPT-4o ...   \n",
              "11  In light of the advancements in Large Language...   \n",
              "\n",
              "                                   retrieved_contexts  \\\n",
              "0   [Simon Willisons Weblog\\n\\nSubscribe\\n\\nThing...   \n",
              "1   [Today $30/mTok gets you OpenAIs most expensi...   \n",
              "2   [These abilities are just a few weeks old at t...   \n",
              "3   [Its become abundantly clear over the course ...   \n",
              "4   [I think this means that, as individual users,...   \n",
              "5   [LLMs need better criticism\\n\\nA lot of people...   \n",
              "6   [Simon Willisons Weblog\\n\\nSubscribe\\n\\nThing...   \n",
              "7   [LLMs need better criticism\\n\\nA lot of people...   \n",
              "8   [Getting back to models that beat GPT-4: Anthr...   \n",
              "9   [Agents still havent really happened yet\\n\\...   \n",
              "10  [Today $30/mTok gets you OpenAIs most expensi...   \n",
              "11  [Simon Willisons Weblog\\n\\nSubscribe\\n\\nThing...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [Prompt driven app generation is a commodity a...   \n",
              "1   [gets you OpenAIs most expensive model, o1. G...   \n",
              "2   [feed with the model and talk about what you c...   \n",
              "3   [dependent on AGI itself. A model thats robus...   \n",
              "4   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "5   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "6   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "7   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "8   [<1-hop>\\n\\nthat. DeepSeek v3 is a huge 685B p...   \n",
              "9   [<1-hop>\\n\\neasy to follow. The rest of the do...   \n",
              "10  [<1-hop>\\n\\nfeed with the model and talk about...   \n",
              "11  [<1-hop>\\n\\nSimon Willisons Weblog Subscribe ...   \n",
              "\n",
              "                                             response  \\\n",
              "0   In 2024, OpenAI made significant advancements ...   \n",
              "1   Anthropic's cheapest model is Claude 3 Haiku, ...   \n",
              "2   The initial challenge with OpenAI's WebSocket ...   \n",
              "3   When someone says a prompt without evals is li...   \n",
              "4   The increased energy efficiency of AI models h...   \n",
              "5   The criticisms of large language models (LLMs)...   \n",
              "6   In 2024, the concept of universal access to AI...   \n",
              "7   LLMs (Large Language Models) need better criti...   \n",
              "8   The Claude 3.5 Sonnet model is noted for its p...   \n",
              "9   Recent advancements in Llama 3.2 models and th...   \n",
              "10  The pricing of GPT-4o is significantly lower t...   \n",
              "11  The advancements in Large Language Models (LLM...   \n",
              "\n",
              "                                            reference  context_recall  \\\n",
              "0   In 2024, OpenAI's GPT-4 model, which was once ...        0.200000   \n",
              "1   Anthropics cheapest model is Claude 3 Haiku, ...        1.000000   \n",
              "2   OpenAI started with a WebSocket API that was q...        1.000000   \n",
              "3   A prompt without the evals, models, and especi...        1.000000   \n",
              "4   The increased energy efficiency of AI models h...             NaN   \n",
              "5   The criticisms of LLMs, especially concerning ...        0.833333   \n",
              "6   In 2024, the concept of universal access to AI...             NaN   \n",
              "7   LLMs need better criticism because there are s...        0.750000   \n",
              "8   Claude 3.5 Sonnet is benchmarked alongside oth...             NaN   \n",
              "9   Recent advancements in Llama 3.2 models have d...             NaN   \n",
              "10  GPT-4o is significantly cheaper than GPT-4, wi...        0.750000   \n",
              "11  Throughout 2024, significant advancements in L...        0.500000   \n",
              "\n",
              "    faithfulness  factual_correctness  answer_relevancy  \\\n",
              "0            NaN                  NaN          0.966099   \n",
              "1       0.666667                 1.00          0.888445   \n",
              "2            NaN                 0.50          0.966881   \n",
              "3            NaN                 0.40          1.000000   \n",
              "4       1.000000                  NaN          0.965649   \n",
              "5       0.516129                 0.32          0.852971   \n",
              "6       0.421053                 0.54          0.954770   \n",
              "7            NaN                 0.63          0.895417   \n",
              "8            NaN                 0.47          0.000000   \n",
              "9       0.647059                 0.56          0.953485   \n",
              "10      0.888889                 0.81          0.917217   \n",
              "11      0.793103                 0.47          0.937482   \n",
              "\n",
              "    context_entity_recall  noise_sensitivity_relevant  \n",
              "0                0.333333                         NaN  \n",
              "1                0.666667                    0.666667  \n",
              "2                1.000000                    0.666667  \n",
              "3                0.000000                    0.000000  \n",
              "4                0.545455                         NaN  \n",
              "5                0.083333                         NaN  \n",
              "6                0.384615                    0.125000  \n",
              "7                0.125000                         NaN  \n",
              "8                0.500000                         NaN  \n",
              "9                0.000000                         NaN  \n",
              "10               0.428571                    0.222222  \n",
              "11               0.250000                    0.275862  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e910d69b-1c5e-404a-b157-f8f5c2b09b0b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>retrieved_contexts</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>response</th>\n",
              "      <th>reference</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>factual_correctness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_entity_recall</th>\n",
              "      <th>noise_sensitivity_relevant</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What advancements has OpenAI made in the field...</td>\n",
              "      <td>[Simon Willisons Weblog\\n\\nSubscribe\\n\\nThing...</td>\n",
              "      <td>[Prompt driven app generation is a commodity a...</td>\n",
              "      <td>In 2024, OpenAI made significant advancements ...</td>\n",
              "      <td>In 2024, OpenAI's GPT-4 model, which was once ...</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.966099</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wht is Anthropic's cheepest model and its cost?</td>\n",
              "      <td>[Today $30/mTok gets you OpenAIs most expensi...</td>\n",
              "      <td>[gets you OpenAIs most expensive model, o1. G...</td>\n",
              "      <td>Anthropic's cheapest model is Claude 3 Haiku, ...</td>\n",
              "      <td>Anthropics cheapest model is Claude 3 Haiku, ...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.888445</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What was the initial challenge with OpenAI's W...</td>\n",
              "      <td>[These abilities are just a few weeks old at t...</td>\n",
              "      <td>[feed with the model and talk about what you c...</td>\n",
              "      <td>The initial challenge with OpenAI's WebSocket ...</td>\n",
              "      <td>OpenAI started with a WebSocket API that was q...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.966881</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What does it mean when someone says a prompt w...</td>\n",
              "      <td>[Its become abundantly clear over the course ...</td>\n",
              "      <td>[dependent on AGI itself. A model thats robus...</td>\n",
              "      <td>When someone says a prompt without evals is li...</td>\n",
              "      <td>A prompt without the evals, models, and especi...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How has the increased energy efficiency of AI ...</td>\n",
              "      <td>[I think this means that, as individual users,...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>The increased energy efficiency of AI models h...</td>\n",
              "      <td>The increased energy efficiency of AI models h...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.965649</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How do the criticisms of LLMs, particularly re...</td>\n",
              "      <td>[LLMs need better criticism\\n\\nA lot of people...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>The criticisms of large language models (LLMs)...</td>\n",
              "      <td>The criticisms of LLMs, especially concerning ...</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.516129</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.852971</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How has the concept of universal access to AI ...</td>\n",
              "      <td>[Simon Willisons Weblog\\n\\nSubscribe\\n\\nThing...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>In 2024, the concept of universal access to AI...</td>\n",
              "      <td>In 2024, the concept of universal access to AI...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.954770</td>\n",
              "      <td>0.384615</td>\n",
              "      <td>0.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Why LLMs need better criticism and what are th...</td>\n",
              "      <td>[LLMs need better criticism\\n\\nA lot of people...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>LLMs (Large Language Models) need better criti...</td>\n",
              "      <td>LLMs need better criticism because there are s...</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.895417</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How does the Claude 3.5 Sonnet compare to othe...</td>\n",
              "      <td>[Getting back to models that beat GPT-4: Anthr...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nthat. DeepSeek v3 is a huge 685B p...</td>\n",
              "      <td>The Claude 3.5 Sonnet model is noted for its p...</td>\n",
              "      <td>Claude 3.5 Sonnet is benchmarked alongside oth...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How have the advancements in Llama 3.2 models ...</td>\n",
              "      <td>[Agents still havent really happened yet\\n\\...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\neasy to follow. The rest of the do...</td>\n",
              "      <td>Recent advancements in Llama 3.2 models and th...</td>\n",
              "      <td>Recent advancements in Llama 3.2 models have d...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.953485</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How do the pricing and capabilities of GPT-4o ...</td>\n",
              "      <td>[Today $30/mTok gets you OpenAIs most expensi...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nfeed with the model and talk about...</td>\n",
              "      <td>The pricing of GPT-4o is significantly lower t...</td>\n",
              "      <td>GPT-4o is significantly cheaper than GPT-4, wi...</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.917217</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>In light of the advancements in Large Language...</td>\n",
              "      <td>[Simon Willisons Weblog\\n\\nSubscribe\\n\\nThing...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nSimon Willisons Weblog Subscribe ...</td>\n",
              "      <td>The advancements in Large Language Models (LLM...</td>\n",
              "      <td>Throughout 2024, significant advancements in L...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.793103</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.937482</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.275862</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e910d69b-1c5e-404a-b157-f8f5c2b09b0b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e910d69b-1c5e-404a-b157-f8f5c2b09b0b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e910d69b-1c5e-404a-b157-f8f5c2b09b0b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a2135676-4239-45f3-bc31-acea335cf830\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a2135676-4239-45f3-bc31-acea335cf830')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a2135676-4239-45f3-bc31-acea335cf830 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_12ac5a29-106e-4a3e-af52-092cfc0bb4c5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result_df2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_12ac5a29-106e-4a3e-af52-092cfc0bb4c5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('result_df2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result_df2",
              "summary": "{\n  \"name\": \"result_df2\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"user_input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"How do the pricing and capabilities of GPT-4o compare to GPT-4, and what impact does this have on the accessibility and environmental concerns of LLMs?\",\n          \"How have the advancements in Llama 3.2 models and the environmental impact of LLMs been addressed in recent AI developments?\",\n          \"What advancements has OpenAI made in the field of large language models, and how do they compare to other organizations' models in 2024?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retrieved_contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference_contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"The pricing of GPT-4o is significantly lower than that of GPT-4, costing $2.50 per million tokens, which is 12 times cheaper than GPT-4's $30 per million tokens. Additionally, GPT-4o mini is priced at $0.15 per million tokens, making it nearly 7 times cheaper than GPT-3.5. This trend of decreasing prices is also seen with other model providers, such as Anthropic and Google, which offer even lower rates, with Google's Gemini 1.5 Flash at $0.075 per million tokens and Gemini 1.5 Flash 8B at $0.0375 per million tokens.\\n\\nThese price reductions are attributed to increased competition among providers and enhanced efficiency in model performance. The efficiency improvements are particularly relevant for those concerned about the environmental impact of large language models (LLMs), as they correlate directly with the energy consumption required to run these models. Lower costs imply that the operational energy usage per prompt is reduced, which can mitigate environmental concerns associated with LLMs.\\n\\nOverall, the combination of reduced pricing and improved capabilities not only makes advanced LLMs more accessible to a wider audience but also addresses some of the environmental issues related to their usage.\",\n          \"Recent advancements in Llama 3.2 models and the environmental impact of large language models (LLMs) have been notable in recent AI developments. \\n\\nFirstly, the Llama 3.2 models have demonstrated significant improvements in training efficiency. For example, while the Llama 3.1 model required 30,840,000 GPU hours for training, the DeepSeek v3 model was trained using only 2,788,000 GPU hours at an estimated cost of about $5.6 million, showcasing a more effective use of resources. This increased efficiency has contributed to a reduction in the energy usage and environmental impact associated with running LLMs, marking a positive trend in this area.\\n\\nFurthermore, it has been reported that the environmental impact of LLMs has improved significantly over the past couple of years. The advancements in model efficiency have allowed for a decrease in the energy consumption required for prompts. OpenAI has also reduced the cost of prompts by 100 times compared to the GPT-3 era, indicating a broader trend toward more sustainable practices within the industry.\\n\\nOverall, these developments reflect a dual focus on enhancing model performance while also addressing the environmental footprint of LLMs, indicating progress in both technological and ecological aspects of AI.\",\n          \"In 2024, OpenAI made significant advancements in the field of large language models (LLMs) with the introduction of their new o1 models, which were initially released as o1-preview and o1-mini. These models build upon the concept of chain-of-thought prompting, incorporating reasoning processes directly into the model. This allows the o1 models to effectively \\\"think through\\\" problems using \\\"reasoning tokens,\\\" which enhances their problem-solving capabilities compared to previous models.\\n\\nAdditionally, the overall landscape of LLMs saw a substantial reduction in prices due to increased efficiency and competition, making advanced models more accessible. Furthermore, the year marked a trend towards multimodal capabilities, with vision becoming common and audio and video functionalities starting to emerge.\\n\\nIn terms of comparison with other organizations' models in 2024, OpenAI's advancements, particularly with the o1 models, positioned them at the forefront of LLM development. The context suggests that while other organizations were making strides, OpenAI's innovations, especially in reasoning capabilities, were noteworthy. However, it is also mentioned that the best currently available LLM was trained in China for significantly less cost, indicating that other organizations were still competitive in some areas. Overall, OpenAI remained a leader in the field, breaking previous barriers and enhancing the functionality of their models.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"GPT-4o is significantly cheaper than GPT-4, with a cost of $2.50, which is 12 times cheaper than GPT-4. Additionally, GPT-4o mini is priced at $0.15 per million tokens, making it nearly 7 times cheaper than GPT-3.5. This reduction in price is attributed to increased competition and efficiency, which also addresses environmental concerns by reducing the energy cost of running prompts. The lower pricing and increased capabilities of GPT-4o make it more accessible to users, although the era of free access to the best models has ended with the introduction of subscription services like ChatGPT Pro.\",\n          \"Recent advancements in Llama 3.2 models have demonstrated significant improvements in efficiency and capability, particularly with their ability to run on smaller devices like iPhones using the MLC Chat iOS app. These models, despite their smaller size of 1B and 3B, perform impressively well, showcasing the potential for high performance in compact models. This development is part of a broader trend in the AI industry towards increasing model efficiency, which has also contributed to a reduction in the environmental impact of running large language models (LLMs). While the environmental impact initially worsened, improvements in training and inference performance have led to more sustainable practices. The focus on efficiency has not only reduced costs but also mitigated some of the environmental concerns associated with LLMs.\",\n          \"In 2024, OpenAI's GPT-4 model, which was once the leading large language model, has been surpassed by models from 18 different organizations on the Chatbot Arena Leaderboard. These organizations include Google, Alibaba, Anthropic, Meta, and others. The advancements in large language models have been significant, with models now capable of handling much longer input contexts, such as Google's Gemini 1.5 Pro, which can accept up to 2 million tokens and input video. This has expanded the scope of problems that can be solved with LLMs. Despite the competition, OpenAI remains a key player in the field, although the achievement of surpassing GPT-4 is no longer as notable as it was in 2023.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.28266728436590194,\n        \"min\": 0.2,\n        \"max\": 1.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.0,\n          0.5,\n          0.8333333333333334\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"faithfulness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2040125345878801,\n        \"min\": 0.42105263157894735,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.6666666666666666,\n          1.0,\n          0.8888888888888888\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"factual_correctness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20094222497468714,\n        \"min\": 0.32,\n        \"max\": 1.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.56,\n          0.5,\n          0.63\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_relevancy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2733819030899048,\n        \"min\": 0.0,\n        \"max\": 0.9999999999999997,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.917216695167848,\n          0.9534845265112973,\n          0.9660991559462543\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_entity_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.29645259863840495,\n        \"min\": 0.0,\n        \"max\": 0.999999995,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.08333333326388888,\n          0.3333333330555555,\n          0.4285714279591837\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"noise_sensitivity_relevant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.28002434386177727,\n        \"min\": 0.0,\n        \"max\": 0.6666666666666666,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0,\n          0.27586206896551724,\n          0.125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w6RT4w1xfcvz",
        "outputId": "ea49e520-7fe8-4fdd-be9e-02905e88955e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           user_input  \\\n",
              "0   What advancements has OpenAI made in the field...   \n",
              "1     Wht is Anthropic's cheepest model and its cost?   \n",
              "2   What was the initial challenge with OpenAI's W...   \n",
              "3   What does it mean when someone says a prompt w...   \n",
              "4   How has the increased energy efficiency of AI ...   \n",
              "5   How do the criticisms of LLMs, particularly re...   \n",
              "6   How has the concept of universal access to AI ...   \n",
              "7   Why LLMs need better criticism and what are th...   \n",
              "8   How does the Claude 3.5 Sonnet compare to othe...   \n",
              "9   How have the advancements in Llama 3.2 models ...   \n",
              "10  How do the pricing and capabilities of GPT-4o ...   \n",
              "11  In light of the advancements in Large Language...   \n",
              "\n",
              "                                   retrieved_contexts  \\\n",
              "0   [OpenAI are not the only game in town here. Go...   \n",
              "1   [Today $30/mTok gets you OpenAIs most expensi...   \n",
              "2   [Did you know ChatGPT has two entirely differe...   \n",
              "3   [Its become abundantly clear over the course ...   \n",
              "4   [The much bigger problem here is the enormous ...   \n",
              "5   [LLMs need better criticism\\n\\nA lot of people...   \n",
              "6   [In 2024, almost every significant model vendo...   \n",
              "7   [LLMs need better criticism\\n\\nA lot of people...   \n",
              "8   [Getting back to models that beat GPT-4: Anthr...   \n",
              "9   [Another common technique is to use larger mod...   \n",
              "10  [Today $30/mTok gets you OpenAIs most expensi...   \n",
              "11  [Since then, almost every major LLM (and most ...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [Prompt driven app generation is a commodity a...   \n",
              "1   [gets you OpenAIs most expensive model, o1. G...   \n",
              "2   [feed with the model and talk about what you c...   \n",
              "3   [dependent on AGI itself. A model thats robus...   \n",
              "4   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "5   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "6   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "7   [<1-hop>\\n\\nPrompt driven app generation is a ...   \n",
              "8   [<1-hop>\\n\\nthat. DeepSeek v3 is a huge 685B p...   \n",
              "9   [<1-hop>\\n\\neasy to follow. The rest of the do...   \n",
              "10  [<1-hop>\\n\\nfeed with the model and talk about...   \n",
              "11  [<1-hop>\\n\\nSimon Willisons Weblog Subscribe ...   \n",
              "\n",
              "                                             response  \\\n",
              "0   In 2024, OpenAI has made significant advanceme...   \n",
              "1   Anthropic's cheapest model is Claude 3 Haiku, ...   \n",
              "2   The initial challenge with OpenAI's WebSocket ...   \n",
              "3   When someone says a prompt without evals is li...   \n",
              "4   The increased energy efficiency of AI models h...   \n",
              "5   The criticisms of LLMs, particularly regarding...   \n",
              "6   In 2024, the concept of universal access to AI...   \n",
              "7   LLMs (Large Language Models) need better criti...   \n",
              "8   The Claude 3.5 Sonnet model is noted for its a...   \n",
              "9   Recent advancements in Llama 3.2 models and th...   \n",
              "10  The pricing and capabilities of GPT-4o are sig...   \n",
              "11  The advancements in Large Language Models (LLM...   \n",
              "\n",
              "                                            reference  context_recall  \\\n",
              "0   In 2024, OpenAI's GPT-4 model, which was once ...        0.000000   \n",
              "1   Anthropics cheapest model is Claude 3 Haiku, ...        1.000000   \n",
              "2   OpenAI started with a WebSocket API that was q...        1.000000   \n",
              "3   A prompt without the evals, models, and especi...        1.000000   \n",
              "4   The increased energy efficiency of AI models h...             NaN   \n",
              "5   The criticisms of LLMs, especially concerning ...             NaN   \n",
              "6   In 2024, the concept of universal access to AI...        0.428571   \n",
              "7   LLMs need better criticism because there are s...             NaN   \n",
              "8   Claude 3.5 Sonnet is benchmarked alongside oth...        0.666667   \n",
              "9   Recent advancements in Llama 3.2 models have d...        0.000000   \n",
              "10  GPT-4o is significantly cheaper than GPT-4, wi...        0.750000   \n",
              "11  Throughout 2024, significant advancements in L...        1.000000   \n",
              "\n",
              "    faithfulness  factual_correctness  answer_relevancy  \\\n",
              "0            NaN                 0.15          0.966099   \n",
              "1            NaN                 1.00          0.945477   \n",
              "2            NaN                 0.50          1.000000   \n",
              "3            NaN                 0.71          1.000000   \n",
              "4            NaN                 0.59          0.945216   \n",
              "5            NaN                 0.37          0.913569   \n",
              "6            NaN                 0.17          0.960220   \n",
              "7            NaN                 0.50          0.909795   \n",
              "8            NaN                 0.53          0.945543   \n",
              "9            NaN                 0.36          0.953485   \n",
              "10      0.523810                 0.71          0.938222   \n",
              "11      0.806452                 0.70          0.952405   \n",
              "\n",
              "    context_entity_recall  noise_sensitivity_relevant  \n",
              "0                0.583333                         NaN  \n",
              "1                0.666667                    0.000000  \n",
              "2                1.000000                    0.333333  \n",
              "3                0.000000                    0.000000  \n",
              "4                     NaN                         NaN  \n",
              "5                0.083333                         NaN  \n",
              "6                     NaN                         NaN  \n",
              "7                     NaN                         NaN  \n",
              "8                0.300000                         NaN  \n",
              "9                0.000000                         NaN  \n",
              "10               0.454545                    0.190476  \n",
              "11               0.187500                         NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-701ab450-538a-443c-972c-086f3643f0d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>retrieved_contexts</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>response</th>\n",
              "      <th>reference</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>factual_correctness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_entity_recall</th>\n",
              "      <th>noise_sensitivity_relevant</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What advancements has OpenAI made in the field...</td>\n",
              "      <td>[OpenAI are not the only game in town here. Go...</td>\n",
              "      <td>[Prompt driven app generation is a commodity a...</td>\n",
              "      <td>In 2024, OpenAI has made significant advanceme...</td>\n",
              "      <td>In 2024, OpenAI's GPT-4 model, which was once ...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.966099</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wht is Anthropic's cheepest model and its cost?</td>\n",
              "      <td>[Today $30/mTok gets you OpenAIs most expensi...</td>\n",
              "      <td>[gets you OpenAIs most expensive model, o1. G...</td>\n",
              "      <td>Anthropic's cheapest model is Claude 3 Haiku, ...</td>\n",
              "      <td>Anthropics cheapest model is Claude 3 Haiku, ...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.945477</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What was the initial challenge with OpenAI's W...</td>\n",
              "      <td>[Did you know ChatGPT has two entirely differe...</td>\n",
              "      <td>[feed with the model and talk about what you c...</td>\n",
              "      <td>The initial challenge with OpenAI's WebSocket ...</td>\n",
              "      <td>OpenAI started with a WebSocket API that was q...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What does it mean when someone says a prompt w...</td>\n",
              "      <td>[Its become abundantly clear over the course ...</td>\n",
              "      <td>[dependent on AGI itself. A model thats robus...</td>\n",
              "      <td>When someone says a prompt without evals is li...</td>\n",
              "      <td>A prompt without the evals, models, and especi...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.71</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How has the increased energy efficiency of AI ...</td>\n",
              "      <td>[The much bigger problem here is the enormous ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>The increased energy efficiency of AI models h...</td>\n",
              "      <td>The increased energy efficiency of AI models h...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.945216</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How do the criticisms of LLMs, particularly re...</td>\n",
              "      <td>[LLMs need better criticism\\n\\nA lot of people...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>The criticisms of LLMs, particularly regarding...</td>\n",
              "      <td>The criticisms of LLMs, especially concerning ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.913569</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How has the concept of universal access to AI ...</td>\n",
              "      <td>[In 2024, almost every significant model vendo...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>In 2024, the concept of universal access to AI...</td>\n",
              "      <td>In 2024, the concept of universal access to AI...</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.960220</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Why LLMs need better criticism and what are th...</td>\n",
              "      <td>[LLMs need better criticism\\n\\nA lot of people...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nPrompt driven app generation is a ...</td>\n",
              "      <td>LLMs (Large Language Models) need better criti...</td>\n",
              "      <td>LLMs need better criticism because there are s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.909795</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How does the Claude 3.5 Sonnet compare to othe...</td>\n",
              "      <td>[Getting back to models that beat GPT-4: Anthr...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nthat. DeepSeek v3 is a huge 685B p...</td>\n",
              "      <td>The Claude 3.5 Sonnet model is noted for its a...</td>\n",
              "      <td>Claude 3.5 Sonnet is benchmarked alongside oth...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.945543</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How have the advancements in Llama 3.2 models ...</td>\n",
              "      <td>[Another common technique is to use larger mod...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\neasy to follow. The rest of the do...</td>\n",
              "      <td>Recent advancements in Llama 3.2 models and th...</td>\n",
              "      <td>Recent advancements in Llama 3.2 models have d...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.953485</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How do the pricing and capabilities of GPT-4o ...</td>\n",
              "      <td>[Today $30/mTok gets you OpenAIs most expensi...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nfeed with the model and talk about...</td>\n",
              "      <td>The pricing and capabilities of GPT-4o are sig...</td>\n",
              "      <td>GPT-4o is significantly cheaper than GPT-4, wi...</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.523810</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.938222</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.190476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>In light of the advancements in Large Language...</td>\n",
              "      <td>[Since then, almost every major LLM (and most ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nSimon Willisons Weblog Subscribe ...</td>\n",
              "      <td>The advancements in Large Language Models (LLM...</td>\n",
              "      <td>Throughout 2024, significant advancements in L...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.806452</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.952405</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-701ab450-538a-443c-972c-086f3643f0d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-701ab450-538a-443c-972c-086f3643f0d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-701ab450-538a-443c-972c-086f3643f0d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c13f6e89-916e-422a-b5d3-f9ea2fd80f1e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c13f6e89-916e-422a-b5d3-f9ea2fd80f1e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c13f6e89-916e-422a-b5d3-f9ea2fd80f1e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_869f53a3-3ff7-4998-b290-836c150c2f1b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_869f53a3-3ff7-4998-b290-836c150c2f1b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('result_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result_df",
              "summary": "{\n  \"name\": \"result_df\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"user_input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"How do the pricing and capabilities of GPT-4o compare to GPT-4, and what impact does this have on the accessibility and environmental concerns of LLMs?\",\n          \"How have the advancements in Llama 3.2 models and the environmental impact of LLMs been addressed in recent AI developments?\",\n          \"What advancements has OpenAI made in the field of large language models, and how do they compare to other organizations' models in 2024?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retrieved_contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference_contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"The pricing and capabilities of GPT-4o are significantly more favorable compared to GPT-4. Specifically, GPT-4o is priced at $2.50 per million tokens, which is 12 times cheaper than GPT-4, while GPT-4o mini is available for $0.15 per million tokens, making it nearly 7 times cheaper than GPT-3.5. This dramatic reduction in cost enhances accessibility for users who may not have been able to afford the more expensive models.\\n\\nThe competitive landscape contributes to these price reductions, with other providers like Anthropic and Google offering even lower pricing for their models, further widening the accessibility gap. For instance, Anthropic's Claude 3 Haiku costs $0.25/mTok, while Google's Gemini models are priced as low as $0.0375/mTok.\\n\\nThese price drops are also linked to increased efficiency in running the models, which addresses environmental concerns related to the energy consumption of large language models (LLMs). As models become cheaper and more energy-efficient, the environmental impact of using LLMs is likely to lessen, making them more sustainable.\\n\\nOverall, the affordability and improved capabilities of newer models like GPT-4o promote broader access to advanced AI tools, while also potentially reducing their environmental footprint.\",\n          \"Recent advancements in Llama 3.2 models and the environmental impact of large language models (LLMs) have been notable in the field of AI. Meta's Llama 3.2 includes multi-modal capabilities, allowing it to process and generate not just text, but also images, audio, and video. This progression reflects a broader trend in 2024 where almost all major model vendors have released multi-modal models, showcasing significant innovation in how LLMs can be applied.\\n\\nThe careful design of training data has become crucial in creating effective models. Instead of indiscriminately scraping large amounts of data from the web, developers are focusing on generating high-quality training data, as seen with Meta's use of over 25 million synthetically generated examples for Llama 3.3.\\n\\nRegarding environmental impact, the training costs associated with LLMs, which include hardware and electricity, have decreased from millions of dollars to tens of thousands. For instance, Microsoft's Phi-2 was trained in 14 days on 96 A100 GPUs, costing around $35,000. This trend indicates a potential reduction in the energy consumption associated with training large models, although the initial costs remain significant.\\n\\nOverall, while the advancements in multi-modal capabilities represent a leap forward in LLM functionality, there remains an ongoing challenge regarding the environmental impact of training such large models. The focus on efficient training data and the decrease in costs may help mitigate some of these environmental concerns in the future.\",\n          \"In 2024, OpenAI has made significant advancements in the field of large language models (LLMs) with the introduction of their o1 models, which include o1-preview and o1-mini, released on September 12th. These models build on the concept of chain-of-thought prompting, where the model is designed to \\\"think out loud\\\" about problems, integrating this reasoning process directly into its structure. This method improves the model's ability to solve problems, providing outputs that are often better than what it could achieve without this reasoning process.\\n\\nDespite these advancements, OpenAI's GPT-4, released in March 2023, remains the benchmark for LLMs, with no other model surpassing it as of late 2024. Although several organizations, including Google and Mistral, are working on models that claim to challenge GPT-4, none have yet demonstrated superior performance.\\n\\nIn comparison, other organizations have also released competitive models. For instance, Google's Gemini-2.0 was launched on December 19, 2023, and Alibaba introduced their QwQ model on November 28, 2023, followed by a vision reasoning model called QvQ on December 24, 2023. DeepSeek's model, DeepSeek-R1-Lite-Preview, became available on November 20, 2023. While many models have emerged, the advancements made by OpenAI, particularly with the o1 models, highlight their ongoing leadership in the field, despite the growing competition from other organizations.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"GPT-4o is significantly cheaper than GPT-4, with a cost of $2.50, which is 12 times cheaper than GPT-4. Additionally, GPT-4o mini is priced at $0.15 per million tokens, making it nearly 7 times cheaper than GPT-3.5. This reduction in price is attributed to increased competition and efficiency, which also addresses environmental concerns by reducing the energy cost of running prompts. The lower pricing and increased capabilities of GPT-4o make it more accessible to users, although the era of free access to the best models has ended with the introduction of subscription services like ChatGPT Pro.\",\n          \"Recent advancements in Llama 3.2 models have demonstrated significant improvements in efficiency and capability, particularly with their ability to run on smaller devices like iPhones using the MLC Chat iOS app. These models, despite their smaller size of 1B and 3B, perform impressively well, showcasing the potential for high performance in compact models. This development is part of a broader trend in the AI industry towards increasing model efficiency, which has also contributed to a reduction in the environmental impact of running large language models (LLMs). While the environmental impact initially worsened, improvements in training and inference performance have led to more sustainable practices. The focus on efficiency has not only reduced costs but also mitigated some of the environmental concerns associated with LLMs.\",\n          \"In 2024, OpenAI's GPT-4 model, which was once the leading large language model, has been surpassed by models from 18 different organizations on the Chatbot Arena Leaderboard. These organizations include Google, Alibaba, Anthropic, Meta, and others. The advancements in large language models have been significant, with models now capable of handling much longer input contexts, such as Google's Gemini 1.5 Pro, which can accept up to 2 million tokens and input video. This has expanded the scope of problems that can be solved with LLMs. Despite the competition, OpenAI remains a key player in the field, although the achievement of surpassing GPT-4 is no longer as notable as it was in 2023.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.41747842316944156,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.0,\n          0.75,\n          0.42857142857142855\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"faithfulness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19985813784688894,\n        \"min\": 0.5238095238095238,\n        \"max\": 0.8064516129032258,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8064516129032258,\n          0.5238095238095238\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"factual_correctness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24272911700581828,\n        \"min\": 0.15,\n        \"max\": 1.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.36,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_relevancy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.027719375404344847,\n        \"min\": 0.909795398896382,\n        \"max\": 0.9999999999999997,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.9382215332666196,\n          0.9534845265112973\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_entity_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.341215232401938,\n        \"min\": 0.0,\n        \"max\": 0.999999995,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.6666666644444444,\n          0.29999999969999996\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"noise_sensitivity_relevant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16206807822747726,\n        \"min\": 0.0,\n        \"max\": 0.3333333333333333,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          0.3333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1QEDyAAq-6M"
      },
      "source": [
        "####  Question:\n",
        "\n",
        "Which system performed better, on what metrics, and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ANSWER\n",
        "\n",
        "#### Result without reranker\n",
        "{'context_recall': 0.6495, 'faithfulness': 0.6651, 'factual_correctness': 0.5242, 'answer_relevancy': 0.9525, 'context_entity_recall': 0.3639, 'noise_sensitivity_relevant': 0.1310}\n",
        "#### Result with reranker\n",
        "{'context_recall': 0.7542, 'faithfulness': 0.7047, 'factual_correctness': 0.5700, 'answer_relevancy': 0.8582, 'context_entity_recall': 0.3597, 'noise_sensitivity_relevant': 0.3261}\n"
      ],
      "metadata": {
        "id": "5Fd9MIZHsFAL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These results are not all reliable because of nan values. Logically, results are supposed to get better sisnce using a reranker improves the quality and relevancy of chunks given to the LLM"
      ],
      "metadata": {
        "id": "1z9K6gYZgDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Full Code"
      ],
      "metadata": {
        "id": "cEQar8vuGdkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "\n",
        "path = \"data/\"\n",
        "loader = DirectoryLoader(path, glob=\"*.html\")\n",
        "docs = loader.load()\n",
        "\n",
        "# Define LLM and Embedder for Synthetic Data Generation using RAGAS\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
        "\n",
        "# Generate Questions dataset\n",
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "dataset = generator.generate_with_langchain_docs(docs, testset_size=10)\n",
        "dataset.to_pandas()\n",
        "\n",
        "################### Build RAg Langchain\n",
        "\n",
        "# Define embedder\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# Define Vector store\n",
        "from langchain_qdrant import QdrantVectorStore\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http.models import Distance, VectorParams\n",
        "\n",
        "client = QdrantClient(\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"ai_across_years\",\n",
        "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
        ")\n",
        "\n",
        "vector_store = QdrantVectorStore(\n",
        "    client=client,\n",
        "    collection_name=\"ai_across_years\",\n",
        "    embedding=embeddings,\n",
        ")\n",
        "\n",
        "# Add chunks to Vector store\n",
        "_ = vector_store.add_documents(documents=split_documents)\n",
        "\n",
        "# Set Vector store as a retriever\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "#Define Retrieval node\n",
        "def retrieve(state):\n",
        "  retrieved_docs = retriever.invoke(state[\"question\"])\n",
        "  return {\"context\" : retrieved_docs}\n",
        "\n",
        "# Create prompt\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_PROMPT = \"\"\"\\\n",
        "You are a helpful assistant who answers questions based on provided context. You must only use the provided context, and cannot use your own knowledge.\n",
        "\n",
        "### Question\n",
        "{question}\n",
        "\n",
        "### Context\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)\n",
        "\n",
        "# Define LLM model for RAG\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "# Define Generation node\n",
        "def generate(state):\n",
        "  docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "  messages = rag_prompt.format_messages(question=state[\"question\"], context=docs_content)\n",
        "  response = llm.invoke(messages)\n",
        "  return {\"response\" : response.content}\n",
        "\n",
        "####################### Build LangGraph\n",
        "\n",
        "# Define State\n",
        "from langgraph.graph import START, StateGraph\n",
        "from typing_extensions import List, TypedDict\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "class State(TypedDict):\n",
        "  question: str\n",
        "  context: List[Document]\n",
        "  response: str\n",
        "\n",
        "# Add nodes as as sequence, add START and compile graph\n",
        "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
        "graph_builder.add_edge(START, \"retrieve\")\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "# Invoke Graph\n",
        "response = graph.invoke({\"question\" : \"How are LLM agents useful?\"})\n",
        "\n",
        "############################\n",
        "\n",
        "# Generate answers for test set questions and add them to the dataset\n",
        "for test_row in dataset:\n",
        "  response = graph.invoke({\"question\" : test_row.eval_sample.user_input})\n",
        "  test_row.eval_sample.response = response[\"response\"]\n",
        "  test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]\n",
        "\n",
        "# Make the dataset as a RAGAS Evaluation Dataset\n",
        "from ragas import EvaluationDataset\n",
        "\n",
        "evaluation_dataset = EvaluationDataset.from_pandas(dataset.to_pandas())\n",
        "\n",
        "# Choose the evaluator LLM\n",
        "from ragas import evaluate\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "\n",
        "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))\n",
        "\n",
        "# Evaluate using RAGAS\n",
        "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n",
        "from ragas import evaluate, RunConfig\n",
        "\n",
        "custom_run_config = RunConfig(timeout=360)\n",
        "\n",
        "result = evaluate(\n",
        "    dataset=evaluation_dataset,\n",
        "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()],\n",
        "    llm=evaluator_llm,\n",
        "    run_config=custom_run_config\n",
        ")\n",
        "result\n",
        "\n",
        "############################################### Add Reranker\n",
        "\n",
        "# Redefine retriever to retrieve 20 chunks instead of 5\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 20})\n",
        "\n",
        "# Re Define Retriever node and add reranker\n",
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "def retrieve_adjusted(state):\n",
        "  compressor = CohereRerank(model=\"rerank-v3.5\")\n",
        "  compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=retriever, search_kwargs={\"k\": 5}\n",
        "  )\n",
        "  retrieved_docs = compression_retriever.invoke(state[\"question\"])\n",
        "  return {\"context\" : retrieved_docs}\n",
        "\n",
        "# Re define state and build new graph using new retriever\n",
        "class State(TypedDict):\n",
        " question: str\n",
        " context: List[Document]\n",
        " response: str\n",
        "\n",
        "graph_builder = StateGraph(State).add_sequence([retrieve_adjusted, generate])\n",
        "graph_builder.add_edge(START, \"retrieve_adjusted\")\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "# Regenerate responses using new retriever with reranekr\n",
        "import time\n",
        "\n",
        "for test_row in dataset:\n",
        "  response = graph.invoke({\"question\" : test_row.eval_sample.user_input})\n",
        "  test_row.eval_sample.response = response[\"response\"]\n",
        "  test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]\n",
        "  time.sleep(2) # To try to avoid rate limiting.\n",
        "\n",
        "evaluation_dataset = EvaluationDataset.from_pandas(dataset.to_pandas())\n",
        "\n",
        "# Evaluate\n",
        "result = evaluate(\n",
        "    dataset=evaluation_dataset,\n",
        "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()],\n",
        "    llm=evaluator_llm,\n",
        "    run_config=custom_run_config\n",
        ")\n",
        "result"
      ],
      "metadata": {
        "id": "5z7br6a1Gg_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lgFXLmu8VgzL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "117883f62a654d6996c2f9f8464cd22b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31981ef797934adebeba357626d4e287": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66e038d8569b43fb8adc5211537fccef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e837089e2ed4366b518306993092ede": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31981ef797934adebeba357626d4e287",
            "max": 72,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66e038d8569b43fb8adc5211537fccef",
            "value": 72
          }
        },
        "a06cc5c232fe415c80c3a468b29ccc66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab759276b57d4de6acefd71e01bcacc6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae2cb8aa76424c01b0e39988cba92f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a06cc5c232fe415c80c3a468b29ccc66",
            "placeholder": "",
            "style": "IPY_MODEL_d06dd06393844bbc8e176fea19a4e142",
            "value": "Evaluating:100%"
          }
        },
        "b09b0c42e0364396aee593f2ba1f18a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae2cb8aa76424c01b0e39988cba92f0a",
              "IPY_MODEL_9e837089e2ed4366b518306993092ede",
              "IPY_MODEL_ccc8bd831acf490bb821cbe9a4d6ce5e"
            ],
            "layout": "IPY_MODEL_d7f40417bcb24600b0e562fe2be29560"
          }
        },
        "ccc8bd831acf490bb821cbe9a4d6ce5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab759276b57d4de6acefd71e01bcacc6",
            "placeholder": "",
            "style": "IPY_MODEL_117883f62a654d6996c2f9f8464cd22b",
            "value": "72/72[04:58&lt;00:00,15.82s/it]"
          }
        },
        "d06dd06393844bbc8e176fea19a4e142": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7f40417bcb24600b0e562fe2be29560": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f6ed158ee714d57a015e175dc8d1074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb42c1780bf143ce99fc4fd5d9552195",
              "IPY_MODEL_1a64719b314441319342706039afeaa5",
              "IPY_MODEL_eba67208fa2d463c80b611c10a764c2b"
            ],
            "layout": "IPY_MODEL_dec4d800cdc748598336de4a5179f9f8"
          }
        },
        "cb42c1780bf143ce99fc4fd5d9552195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d974d2c41fe4f87abf558752c52ff22",
            "placeholder": "",
            "style": "IPY_MODEL_ac4d0e3f185b448e9ae8f1a69aac9c9a",
            "value": "ApplyingHeadlinesExtractor:100%"
          }
        },
        "1a64719b314441319342706039afeaa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02b895c7622a4e1289181c0daccb7d16",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81bd7a5831504edca34934746239a4d5",
            "value": 2
          }
        },
        "eba67208fa2d463c80b611c10a764c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_045876c0ffc349cfa7a219156cc562d5",
            "placeholder": "",
            "style": "IPY_MODEL_7b563c1b2ed8429093077b52df64c3c3",
            "value": "2/2[00:03&lt;00:00,1.46s/it]"
          }
        },
        "dec4d800cdc748598336de4a5179f9f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "7d974d2c41fe4f87abf558752c52ff22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac4d0e3f185b448e9ae8f1a69aac9c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02b895c7622a4e1289181c0daccb7d16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81bd7a5831504edca34934746239a4d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "045876c0ffc349cfa7a219156cc562d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b563c1b2ed8429093077b52df64c3c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc1d72296b974395a03d2beacbe3fe49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_419683ea18d74012a3af5f7fbceb7e6a",
              "IPY_MODEL_52307c7ed2b249b88fa8984cc35c5b6f",
              "IPY_MODEL_3a60c28ca47f4f03bbe8fb6254dcc31e"
            ],
            "layout": "IPY_MODEL_621c1fe3c8df4afaa60210f3a21be202"
          }
        },
        "419683ea18d74012a3af5f7fbceb7e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cce3960468fe425eb9749aaae123f1c3",
            "placeholder": "",
            "style": "IPY_MODEL_26f1876c12494fcab17bbb518682f2d0",
            "value": "ApplyingHeadlineSplitter:50%"
          }
        },
        "52307c7ed2b249b88fa8984cc35c5b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea4622e501514546ab72e573ef7d3779",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b9368b33a4b4df9ac2b538258eccbb3",
            "value": 2
          }
        },
        "3a60c28ca47f4f03bbe8fb6254dcc31e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b6cc06adf804d69819c9e5172f9faee",
            "placeholder": "",
            "style": "IPY_MODEL_b469015d79db423e84d10a4d4b6ebe27",
            "value": "1/2[00:00&lt;00:00,9.43it/s]"
          }
        },
        "621c1fe3c8df4afaa60210f3a21be202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "cce3960468fe425eb9749aaae123f1c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26f1876c12494fcab17bbb518682f2d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea4622e501514546ab72e573ef7d3779": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b9368b33a4b4df9ac2b538258eccbb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b6cc06adf804d69819c9e5172f9faee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b469015d79db423e84d10a4d4b6ebe27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "346bf493b1c146729ec8719e9c6add72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95868ebefccd41739b828860cb76fe48",
              "IPY_MODEL_80b7e73d6b0140a0b81d2dae7de5fc8e",
              "IPY_MODEL_f34ac2d41036487b86df330b5d499d8f"
            ],
            "layout": "IPY_MODEL_b4218459e5884b328191982138e4d8ab"
          }
        },
        "95868ebefccd41739b828860cb76fe48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12bf4c503cad4fc6accaac5b63a33efc",
            "placeholder": "",
            "style": "IPY_MODEL_efa5784498d4451280bd7e520fc169b3",
            "value": "ApplyingSummaryExtractor:100%"
          }
        },
        "80b7e73d6b0140a0b81d2dae7de5fc8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc4da7da6bd84e2290bea6ddb73b3b8e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed45493d967f431fa7f99b56574ec7c0",
            "value": 2
          }
        },
        "f34ac2d41036487b86df330b5d499d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baa82b2330914bc9aaec648427183489",
            "placeholder": "",
            "style": "IPY_MODEL_9a21192b7f0a4bb1a482df32c8b1674f",
            "value": "2/2[00:05&lt;00:00,2.32s/it]"
          }
        },
        "b4218459e5884b328191982138e4d8ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "12bf4c503cad4fc6accaac5b63a33efc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efa5784498d4451280bd7e520fc169b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc4da7da6bd84e2290bea6ddb73b3b8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed45493d967f431fa7f99b56574ec7c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "baa82b2330914bc9aaec648427183489": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a21192b7f0a4bb1a482df32c8b1674f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efc621dc3bba4f7391482b6c8100036c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e13e79cb3c9949c8be95a191faf4939b",
              "IPY_MODEL_57257089303244d587f1e36ad17866de",
              "IPY_MODEL_fda6085ab28a4f00a0ad37e3e6fba913"
            ],
            "layout": "IPY_MODEL_4553b364be5d425ca80e4819f48f4121"
          }
        },
        "e13e79cb3c9949c8be95a191faf4939b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3263d40172984ece820490056b02e559",
            "placeholder": "",
            "style": "IPY_MODEL_ddfdc13c8f0d497ca4ff9e19d130b10d",
            "value": "ApplyingCustomNodeFilter:100%"
          }
        },
        "57257089303244d587f1e36ad17866de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6a39f84177f40a3813c28b4c3691e5a",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_528e64c47f1942618edb70c60e8656e2",
            "value": 12
          }
        },
        "fda6085ab28a4f00a0ad37e3e6fba913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47361f0e9c0f4543b217701d9be8a74b",
            "placeholder": "",
            "style": "IPY_MODEL_31d83715805a4bd481975796b667d36a",
            "value": "12/12[00:31&lt;00:00,3.44s/it]"
          }
        },
        "4553b364be5d425ca80e4819f48f4121": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "3263d40172984ece820490056b02e559": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddfdc13c8f0d497ca4ff9e19d130b10d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6a39f84177f40a3813c28b4c3691e5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "528e64c47f1942618edb70c60e8656e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47361f0e9c0f4543b217701d9be8a74b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31d83715805a4bd481975796b667d36a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5309a59d155840efbb13e1cdc1bfb92b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c1e58660719468ba4035ebd89bfe7b4",
              "IPY_MODEL_a79375eefc8d41e29d6c6fa67f77f922",
              "IPY_MODEL_5d4834d9ab96428bb9f43c30d0ad8e9d"
            ],
            "layout": "IPY_MODEL_5422f1367de54bc99753cce6ea3a93a7"
          }
        },
        "6c1e58660719468ba4035ebd89bfe7b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86884bda9daf4d4f87870a5f180ad006",
            "placeholder": "",
            "style": "IPY_MODEL_fbee8356be144e4e913bc6bb3385f61d",
            "value": "Applying[EmbeddingExtractor,ThemesExtractor,NERExtractor]:100%"
          }
        },
        "a79375eefc8d41e29d6c6fa67f77f922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3faf9cfd273c46ce85f0947b42e0c25a",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1d167c67e72404cad05daa01ee14705",
            "value": 26
          }
        },
        "5d4834d9ab96428bb9f43c30d0ad8e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b5fbaa9d4ad4d5e9f22f4f0c2643ef1",
            "placeholder": "",
            "style": "IPY_MODEL_eb2eb7cad66a49778bdf4567803a26fd",
            "value": "26/26[02:05&lt;00:00,19.77s/it]"
          }
        },
        "5422f1367de54bc99753cce6ea3a93a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "86884bda9daf4d4f87870a5f180ad006": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbee8356be144e4e913bc6bb3385f61d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3faf9cfd273c46ce85f0947b42e0c25a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1d167c67e72404cad05daa01ee14705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b5fbaa9d4ad4d5e9f22f4f0c2643ef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb2eb7cad66a49778bdf4567803a26fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e89d6ef0b06d44b897876e8f07397980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6edb3971184f449d9d22ea06e4f2cb99",
              "IPY_MODEL_585d7e95ac77494c99554aceaf595e63",
              "IPY_MODEL_001a033727a9426e8cc4b0d3ffa3cee6"
            ],
            "layout": "IPY_MODEL_d29265448516400281a9fd9b14984bd4"
          }
        },
        "6edb3971184f449d9d22ea06e4f2cb99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fda1054fea04125a88b5e6e8d0f0899",
            "placeholder": "",
            "style": "IPY_MODEL_d4b3e2d4ac7c46d0aeef3881feae06f5",
            "value": "Applying[CosineSimilarityBuilder,OverlapScoreBuilder]:0%"
          }
        },
        "585d7e95ac77494c99554aceaf595e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca52e18515f1407c9b80e63e66e38f5e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a448799f69f4d3aaec11679886c794e",
            "value": 2
          }
        },
        "001a033727a9426e8cc4b0d3ffa3cee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d273af6f9ec94f049ba06f0971c61d7c",
            "placeholder": "",
            "style": "IPY_MODEL_9c9be8eed31d4067a3eab74fa97f9269",
            "value": "0/2[00:00&lt;?,?it/s]"
          }
        },
        "d29265448516400281a9fd9b14984bd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "1fda1054fea04125a88b5e6e8d0f0899": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4b3e2d4ac7c46d0aeef3881feae06f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca52e18515f1407c9b80e63e66e38f5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a448799f69f4d3aaec11679886c794e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d273af6f9ec94f049ba06f0971c61d7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c9be8eed31d4067a3eab74fa97f9269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbeb65d396d141fd908ed6ad61d46434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75edd75dc5614193b2fb6f9ae60edbc4",
              "IPY_MODEL_cd26269e258f4ac08965543ebd75f65d",
              "IPY_MODEL_a156ba773dd3413fa33d61136419a44b"
            ],
            "layout": "IPY_MODEL_0944f1eea3c24f40be3953a7233aab7e"
          }
        },
        "75edd75dc5614193b2fb6f9ae60edbc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c594f560f7148cea8a46166f2edc55a",
            "placeholder": "",
            "style": "IPY_MODEL_a59981d0f93f45a5a1b9a70f323565c6",
            "value": "Generatingpersonas:100%"
          }
        },
        "cd26269e258f4ac08965543ebd75f65d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_079463ef12a443108fc46acc205e37db",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4694f047b45a4b38bb2ebbeca2e16a15",
            "value": 2
          }
        },
        "a156ba773dd3413fa33d61136419a44b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad96255cb05e4cadb63a39979a4679e1",
            "placeholder": "",
            "style": "IPY_MODEL_59273683ec9b44839b503ec23629148c",
            "value": "2/2[00:01&lt;00:00,1.19it/s]"
          }
        },
        "0944f1eea3c24f40be3953a7233aab7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c594f560f7148cea8a46166f2edc55a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a59981d0f93f45a5a1b9a70f323565c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "079463ef12a443108fc46acc205e37db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4694f047b45a4b38bb2ebbeca2e16a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad96255cb05e4cadb63a39979a4679e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59273683ec9b44839b503ec23629148c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f02a044d69494e31b4971b6b28b0b40b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0493d8206c4c4a3490aaee0e039b7fa3",
              "IPY_MODEL_1e713b3b96ed4af7a570d24274d82aef",
              "IPY_MODEL_9f7f2b66957e4975960990a11903859d"
            ],
            "layout": "IPY_MODEL_3aaab9d5aa354685a3b4fd1a66da8f27"
          }
        },
        "0493d8206c4c4a3490aaee0e039b7fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2d4d15ada6b41e8838c7547a1496023",
            "placeholder": "",
            "style": "IPY_MODEL_b035f9e28e894e019664988458943c57",
            "value": "GeneratingScenarios:100%"
          }
        },
        "1e713b3b96ed4af7a570d24274d82aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b12d8cbf7274575a516bdbac4bbca70",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00af77119df9499594e6c7c52205f0ce",
            "value": 3
          }
        },
        "9f7f2b66957e4975960990a11903859d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20c24e354e944b399af17cfdd19e05bb",
            "placeholder": "",
            "style": "IPY_MODEL_04fbb6e5dd9a4d2f962460293d440db6",
            "value": "3/3[00:11&lt;00:00,3.84s/it]"
          }
        },
        "3aaab9d5aa354685a3b4fd1a66da8f27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2d4d15ada6b41e8838c7547a1496023": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b035f9e28e894e019664988458943c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b12d8cbf7274575a516bdbac4bbca70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00af77119df9499594e6c7c52205f0ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20c24e354e944b399af17cfdd19e05bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04fbb6e5dd9a4d2f962460293d440db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b2a95b93f28430b9a76b4bfc82f07a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5db0d833c6e54d43be635c36bfd376a9",
              "IPY_MODEL_6503d2d3920e4e3b86cd1f4f80aed818",
              "IPY_MODEL_477a27aa344946f4aa77c3da7428b746"
            ],
            "layout": "IPY_MODEL_6743c3ce8f794051a8d555eceddda15f"
          }
        },
        "5db0d833c6e54d43be635c36bfd376a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cf2b6b9a08544d0a2a775481c3c6120",
            "placeholder": "",
            "style": "IPY_MODEL_750134f23399437980f8fd757ed034f2",
            "value": "GeneratingSamples:100%"
          }
        },
        "6503d2d3920e4e3b86cd1f4f80aed818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9b1fe1ad4f64cff88240470c7442e86",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66f2eb93aa334c1da8226f15ecc91840",
            "value": 12
          }
        },
        "477a27aa344946f4aa77c3da7428b746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c657153e7bca482193cd3b424627c07f",
            "placeholder": "",
            "style": "IPY_MODEL_67837c39ac9440c18997de05a3334b9b",
            "value": "12/12[00:14&lt;00:00,1.56s/it]"
          }
        },
        "6743c3ce8f794051a8d555eceddda15f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cf2b6b9a08544d0a2a775481c3c6120": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "750134f23399437980f8fd757ed034f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9b1fe1ad4f64cff88240470c7442e86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66f2eb93aa334c1da8226f15ecc91840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c657153e7bca482193cd3b424627c07f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67837c39ac9440c18997de05a3334b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3aaf433ef94428c9fe4435777f21ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21decbb1ed234b50a15ca317da804252",
              "IPY_MODEL_b2bc6ffb19a24df28605a05cc6bd4d70",
              "IPY_MODEL_52d51d531ffd4bb38b905a92eb9ab9f1"
            ],
            "layout": "IPY_MODEL_959dd7ebf9554086975b1de7e35f09db"
          }
        },
        "21decbb1ed234b50a15ca317da804252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaa622189dab43deac89985ad8663f53",
            "placeholder": "",
            "style": "IPY_MODEL_b9a6e5abcfed4cff85d598e031e29d08",
            "value": "Evaluating:100%"
          }
        },
        "b2bc6ffb19a24df28605a05cc6bd4d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be7c52d2cef74dc3bddc299bbbc0507a",
            "max": 72,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_201696f69a7042b9a78e4e1071349e8b",
            "value": 72
          }
        },
        "52d51d531ffd4bb38b905a92eb9ab9f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccfac9a890cb4b8f81b027b236d71e68",
            "placeholder": "",
            "style": "IPY_MODEL_361d10784ede44baad334e340b95b483",
            "value": "72/72[13:21&lt;00:00,35.94s/it]"
          }
        },
        "959dd7ebf9554086975b1de7e35f09db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaa622189dab43deac89985ad8663f53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9a6e5abcfed4cff85d598e031e29d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be7c52d2cef74dc3bddc299bbbc0507a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "201696f69a7042b9a78e4e1071349e8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccfac9a890cb4b8f81b027b236d71e68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "361d10784ede44baad334e340b95b483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8368a3dda89b42ebbcaa5c29a7af46a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a72df0f04764852a2eccd4719d96447",
              "IPY_MODEL_b6ecf12652c845bead91ed1850639163",
              "IPY_MODEL_5ca29705e23c4191b291ba441c76c108"
            ],
            "layout": "IPY_MODEL_9f824f9ca8c3455bb0840b5e2b0e7a4b"
          }
        },
        "6a72df0f04764852a2eccd4719d96447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b050cc565cf74497954b4cd9338152cd",
            "placeholder": "",
            "style": "IPY_MODEL_c641cabb4fbf4ff09a1d5615d36238b8",
            "value": "Evaluating:100%"
          }
        },
        "b6ecf12652c845bead91ed1850639163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3f1d20338494509a53c3491b80b3317",
            "max": 72,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dcbb8834fd7b4ed1a830cf8257f33629",
            "value": 72
          }
        },
        "5ca29705e23c4191b291ba441c76c108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8345c31700364316ae6fa13933d2f801",
            "placeholder": "",
            "style": "IPY_MODEL_650d3121b13744c8a381d1bd4db3e078",
            "value": "72/72[11:30&lt;00:00,40.73s/it]"
          }
        },
        "9f824f9ca8c3455bb0840b5e2b0e7a4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b050cc565cf74497954b4cd9338152cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c641cabb4fbf4ff09a1d5615d36238b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3f1d20338494509a53c3491b80b3317": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcbb8834fd7b4ed1a830cf8257f33629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8345c31700364316ae6fa13933d2f801": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "650d3121b13744c8a381d1bd4db3e078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}